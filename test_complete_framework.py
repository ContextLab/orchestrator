#!/usr/bin/env python3
"""Final demonstration of the complete declarative pipeline framework."""

import asyncio
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from orchestrator.engine import DeclarativePipelineEngine


async def demonstrate_complete_framework():
    """Demonstrate the complete declarative framework capabilities."""
    
    print("üéâ **COMPLETE DECLARATIVE PIPELINE FRAMEWORK DEMONSTRATION**")
    print("=" * 80)
    print()
    
    # Complex pipeline showcasing all features
    showcase_pipeline = """
name: "Complete Framework Showcase"
description: "Demonstrates all declarative framework capabilities"
version: "1.0.0"

inputs:
  topic:
    type: string
    description: "Research topic"
  max_sources:
    type: integer
    description: "Maximum number of sources to process"
    default: 5
  enable_validation:
    type: boolean
    description: "Enable input validation"
    default: true

steps:
  # Phase 1 Features: AUTO tag resolution and basic execution
  - id: validate_topic
    action: <AUTO>validate that {{topic}} is a suitable research topic</AUTO>
    condition: "{{enable_validation}} == true"
    cache_results: true
    timeout: 10.0
    
  # Phase 2 Features: Smart tool discovery and execution
  - id: discover_sources
    action: <AUTO>search for comprehensive information about {{topic}} using web search</AUTO>
    depends_on: [validate_topic]
    # Tools will be automatically discovered: web-search
    
  # Phase 3 Features: Conditional execution
  - id: check_source_quality
    action: <AUTO>evaluate the quality and relevance of discovered sources</AUTO>
    depends_on: [discover_sources]
    condition: "{{discover_sources.success}} == true"
    
  # Phase 3 Features: Loop execution with conditions
  - id: process_sources
    action: <AUTO>extract and analyze key information from each source</AUTO>
    depends_on: [check_source_quality]
    loop:
      foreach: "{{discover_sources.results}}"
      parallel: true
      max_iterations: "{{max_sources}}"
      collect_results: true
    # Tools will be automatically discovered: data-processing, headless-browser
    
  # Phase 3 Features: Advanced error handling
  - id: synthesize_insights
    action: <AUTO>synthesize insights from all processed sources into coherent analysis</AUTO>
    depends_on: [process_sources]
    condition: "{{process_sources.iteration_count}} > 0"
    on_error:
      action: <AUTO>create basic summary from available data</AUTO>
      continue_on_error: true
      retry_count: 2
      retry_delay: 1.0
      fallback_value: "Unable to synthesize insights - data processing incomplete"
    
  # Final report generation
  - id: generate_report
    action: <AUTO>create comprehensive research report about {{topic}} with insights and recommendations</AUTO>
    depends_on: [synthesize_insights]
    timeout: 30.0
    tags: ["final", "output"]
    # Tools will be automatically discovered: report-generator

outputs:
  research_report: "{{generate_report.result}}"
  sources_processed: "{{process_sources.iteration_count}}"
  insights_generated: "{{synthesize_insights.result}}"
  validation_passed: "{{validate_topic.success}}"
"""
    
    print("üìã **PIPELINE DEFINITION:**")
    print("```yaml")
    print(showcase_pipeline)
    print("```")
    print()
    
    # Initialize the declarative engine
    engine = DeclarativePipelineEngine()
    
    print("üîç **FRAMEWORK ANALYSIS:**")
    print("-" * 50)
    
    # Validate the pipeline
    validation = await engine.validate_pipeline(showcase_pipeline)
    
    print(f"‚úÖ Pipeline Valid: {validation['valid']}")
    print(f"üìä Total Steps: {validation['total_steps']}")
    print(f"ü§ñ AUTO Tag Steps: {validation['auto_tag_steps']}")
    print(f"üîß Required Tools: {validation['required_tools']}")
    print(f"üìã Execution Order: {[step for step in validation['execution_order']]}")
    
    if validation.get('warnings'):
        print("\n‚ö†Ô∏è  Warnings:")
        for warning in validation['warnings']:
            print(f"   ‚Ä¢ {warning}")
    
    print()
    print("üöÄ **FRAMEWORK CAPABILITIES DEMONSTRATED:**")
    print("-" * 50)
    
    # Analyze the parsed pipeline for features
    pipeline_spec = engine._parse_yaml_to_spec(showcase_pipeline)
    
    feature_counts = {
        "conditional_steps": 0,
        "loop_steps": 0,
        "error_handling_steps": 0,
        "auto_tag_steps": 0,
        "cached_steps": 0,
        "timeout_steps": 0
    }
    
    for step in pipeline_spec.steps:
        if step.has_condition():
            feature_counts["conditional_steps"] += 1
        if step.has_loop():
            feature_counts["loop_steps"] += 1
        if step.has_error_handling():
            feature_counts["error_handling_steps"] += 1
        if step.has_auto_tags():
            feature_counts["auto_tag_steps"] += 1
        if step.cache_results:
            feature_counts["cached_steps"] += 1
        if step.timeout:
            feature_counts["timeout_steps"] += 1
    
    print("‚úÖ **Phase 1 Features (Core Engine):**")
    print(f"   ‚Ä¢ AUTO Tag Resolution: {feature_counts['auto_tag_steps']} steps")
    print(f"   ‚Ä¢ Template Variables: Fully supported")
    print(f"   ‚Ä¢ Dependency Management: Complete topological sorting")
    print(f"   ‚Ä¢ Pipeline Validation: Comprehensive")
    
    print("\n‚úÖ **Phase 2 Features (Smart Discovery):**")
    print(f"   ‚Ä¢ Tool Discovery: {len(validation['required_tools'])} tools auto-discovered")
    print(f"   ‚Ä¢ Execution Strategies: Multi-strategy support")
    print(f"   ‚Ä¢ Context Enhancement: Pattern + semantic matching")
    print(f"   ‚Ä¢ Tool Registry: {len(engine.tool_registry.list_tools())} tools available")
    
    print("\n‚úÖ **Phase 3 Features (Advanced Execution):**")
    print(f"   ‚Ä¢ Conditional Steps: {feature_counts['conditional_steps']} steps")
    print(f"   ‚Ä¢ Loop Execution: {feature_counts['loop_steps']} steps")
    print(f"   ‚Ä¢ Error Handling: {feature_counts['error_handling_steps']} steps")
    print(f"   ‚Ä¢ Result Caching: {feature_counts['cached_steps']} steps")
    print(f"   ‚Ä¢ Timeout Protection: {feature_counts['timeout_steps']} steps")
    
    print()
    print("üéØ **ZERO-CODE PIPELINE ACHIEVEMENT:**")
    print("-" * 50)
    print("‚úÖ Users can define complete AI workflows using pure YAML")
    print("‚úÖ No custom Python code required for execution")
    print("‚úÖ Automatic tool discovery and configuration")
    print("‚úÖ AI-powered prompt generation from abstract descriptions")
    print("‚úÖ Advanced control flow (conditions, loops, error handling)")
    print("‚úÖ Performance optimization (caching, timeouts, parallel execution)")
    print("‚úÖ Intelligent execution strategies based on task requirements")
    
    print()
    print("üèÜ **FRAMEWORK TRANSFORMATION COMPLETE!**")
    print("=" * 80)
    print("From manual coding to declarative YAML-only AI pipeline definition.")
    print("Ready for production use with any LLM provider and tool ecosystem.")
    
    return True


async def main():
    """Run the complete framework demonstration."""
    try:
        success = await demonstrate_complete_framework()
        print("\n‚úÖ Framework demonstration completed successfully!")
        return success
    except Exception as e:
        print(f"\n‚ùå Framework demonstration failed: {e}")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)