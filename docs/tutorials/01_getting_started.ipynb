{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with Orchestrator Framework\n",
        "\n",
        "This tutorial introduces the core concepts of the Orchestrator framework for building AI/LLM workflows.\n",
        "\n",
        "## What is Orchestrator?\n",
        "\n",
        "Orchestrator is a powerful Python framework for creating, managing, and executing complex AI workflows. It provides:\n",
        "\n",
        "- **Task Management**: Define and organize individual work units\n",
        "- **Pipeline Orchestration**: Create dependency graphs between tasks\n",
        "- **Model Integration**: Work with multiple AI models (OpenAI, Anthropic, local models)\n",
        "- **State Management**: Checkpoint and resume workflows\n",
        "- **YAML Configuration**: Define workflows declaratively\n",
        "\n",
        "## Installation\n",
        "\n",
        "First, make sure you have the orchestrator package installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# If running from the repository root\nimport sys\nsys.path.insert(0, '../src')\n\n# Import core components\nimport os\nfrom orchestrator.core.task import Task\nfrom orchestrator.core.pipeline import Pipeline\nfrom orchestrator.models.openai_model import OpenAIModel\nfrom orchestrator.utils.api_keys import load_api_keys\nfrom orchestrator.orchestrator import Orchestrator\nfrom orchestrator.state.state_manager import InMemoryStateManager\n\nprint(\"\u2705 Orchestrator imported successfully!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Core Concepts\n",
        "\n",
        "### 1. Tasks\n",
        "\n",
        "Tasks are the fundamental building blocks of workflows. Each task represents a single operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple task\n",
        "task = Task(\n",
        "    id=\"hello_world\",\n",
        "    name=\"Hello World Task\",\n",
        "    action=\"generate\",\n",
        "    parameters={\n",
        "        \"prompt\": \"Say hello to the world\",\n",
        "        \"max_tokens\": 50\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"Task ID: {task.id}\")\n",
        "print(f\"Task Name: {task.name}\")\n",
        "print(f\"Task Status: {task.status}\")\n",
        "print(f\"Task Parameters: {task.parameters}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 2. Models\n\nModels represent AI/LLM backends that can execute tasks. Let's create a real model using OpenAI:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Load API keys from environment\nload_api_keys()\n\n# Create a real OpenAI model\nmodel = OpenAIModel(\n    name=\"gpt-3.5-turbo\",\n    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # Loaded from environment\n)\n\nprint(f\"Model: {model.name}\")\nprint(f\"Provider: OpenAI\")\nprint(f\"Ready for real AI interactions!\")\n\n# Note: Make sure you have set your OPENAI_API_KEY environment variable\n# You can also use AnthropicModel with ANTHROPIC_API_KEY if preferred"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Pipelines\n",
        "\n",
        "Pipelines organize tasks and define their execution order through dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple pipeline\n",
        "pipeline = Pipeline(\n",
        "    id=\"demo_pipeline\",\n",
        "    name=\"Demo Pipeline\",\n",
        "    description=\"A simple demonstration pipeline\"\n",
        ")\n",
        "\n",
        "# Add our task to the pipeline\n",
        "pipeline.add_task(task)\n",
        "\n",
        "print(f\"Pipeline: {pipeline.name}\")\n",
        "print(f\"Number of tasks: {len(pipeline)}\")\n",
        "print(f\"Tasks: {list(pipeline)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Orchestrator\n",
        "\n",
        "The Orchestrator coordinates execution of pipelines using models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an orchestrator with in-memory state management\n",
        "state_manager = InMemoryStateManager()\n",
        "orchestrator = Orchestrator(state_manager=state_manager)\n",
        "\n",
        "# Register our model\n",
        "orchestrator.register_model(model)\n",
        "\n",
        "print(f\"Orchestrator created with {len(orchestrator.models)} model(s)\")\n",
        "print(f\"Available models: {list(orchestrator.models.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running Your First Pipeline\n",
        "\n",
        "Now let's execute our pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "async def run_pipeline():\n",
        "    \"\"\"Execute the demo pipeline.\"\"\"\n",
        "    result = await orchestrator.execute_pipeline(pipeline)\n",
        "    return result\n",
        "\n",
        "# Run the pipeline\n",
        "result = await run_pipeline()\n",
        "\n",
        "print(f\"Pipeline execution result: {result}\")\n",
        "print(f\"Task status: {task.status}\")\n",
        "print(f\"Task result: {task.result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building a Multi-Task Pipeline\n",
        "\n",
        "Let's create a more complex pipeline with multiple tasks and dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a complex pipeline\n",
        "complex_pipeline = Pipeline(\n",
        "    id=\"analysis_pipeline\",\n",
        "    name=\"Text Analysis Pipeline\",\n",
        "    description=\"Analyze text through multiple steps\"\n",
        ")\n",
        "\n",
        "# Task 1: Generate content\n",
        "generate_task = Task(\n",
        "    id=\"generate_content\",\n",
        "    name=\"Generate Content\",\n",
        "    action=\"generate\",\n",
        "    parameters={\n",
        "        \"prompt\": \"Write a short story about a robot learning to paint\",\n",
        "        \"max_tokens\": 200\n",
        "    }\n",
        ")\n",
        "\n",
        "# Task 2: Analyze sentiment (depends on task 1)\n",
        "sentiment_task = Task(\n",
        "    id=\"analyze_sentiment\",\n",
        "    name=\"Analyze Sentiment\",\n",
        "    action=\"analyze\",\n",
        "    parameters={\n",
        "        \"prompt\": \"Analyze the sentiment of this text: {generate_content.result}\",\n",
        "        \"analysis_type\": \"sentiment\"\n",
        "    },\n",
        "    dependencies=[\"generate_content\"]\n",
        ")\n",
        "\n",
        "# Task 3: Extract themes (depends on task 1)\n",
        "theme_task = Task(\n",
        "    id=\"extract_themes\",\n",
        "    name=\"Extract Themes\",\n",
        "    action=\"analyze\",\n",
        "    parameters={\n",
        "        \"prompt\": \"Extract the main themes from this text: {generate_content.result}\",\n",
        "        \"analysis_type\": \"themes\"\n",
        "    },\n",
        "    dependencies=[\"generate_content\"]\n",
        ")\n",
        "\n",
        "# Task 4: Summarize analysis (depends on tasks 2 and 3)\n",
        "summary_task = Task(\n",
        "    id=\"summarize_analysis\",\n",
        "    name=\"Summarize Analysis\",\n",
        "    action=\"generate\",\n",
        "    parameters={\n",
        "        \"prompt\": \"Summarize this analysis: Sentiment: {analyze_sentiment.result}, Themes: {extract_themes.result}\",\n",
        "        \"max_tokens\": 100\n",
        "    },\n",
        "    dependencies=[\"analyze_sentiment\", \"extract_themes\"]\n",
        ")\n",
        "\n",
        "# Add tasks to pipeline\n",
        "for task in [generate_task, sentiment_task, theme_task, summary_task]:\n",
        "    complex_pipeline.add_task(task)\n",
        "\n",
        "print(f\"Complex pipeline created with {len(complex_pipeline)} tasks\")\n",
        "print(f\"Tasks: {list(complex_pipeline)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's visualize the execution order:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the execution order\n",
        "execution_order = complex_pipeline.get_execution_order()\n",
        "\n",
        "print(\"Execution order (parallel groups):\")\n",
        "for i, level in enumerate(execution_order):\n",
        "    print(f\"  Level {i+1}: {level}\")\n",
        "\n",
        "# Get the critical path\n",
        "critical_path = complex_pipeline.get_critical_path()\n",
        "print(f\"\\nCritical path: {' -> '.join(critical_path)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Now let's execute the complex pipeline with real AI responses:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Real models generate responses dynamically - no need to set up canned responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's execute the complex pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def run_complex_pipeline():\n",
        "    \"\"\"Execute the complex analysis pipeline.\"\"\"\n",
        "    print(\"\ud83d\ude80 Starting complex pipeline execution...\\n\")\n",
        "    \n",
        "    # Execute the pipeline\n",
        "    result = await orchestrator.execute_pipeline(complex_pipeline)\n",
        "    \n",
        "    print(f\"\\n\u2705 Pipeline execution completed with result: {result}\\n\")\n",
        "    \n",
        "    # Show results for each task\n",
        "    print(\"\ud83d\udcca Task Results:\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    for task_id in execution_order[0] + execution_order[1] + execution_order[2]:\n",
        "        task = complex_pipeline.get_task(task_id)\n",
        "        print(f\"\\n\ud83d\udd38 {task.name} ({task.id})\")\n",
        "        print(f\"   Status: {task.status}\")\n",
        "        if task.result:\n",
        "            # Truncate long results for display\n",
        "            result_text = task.result[:200] + \"...\" if len(task.result) > 200 else task.result\n",
        "            print(f\"   Result: {result_text}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Execute the complex pipeline\n",
        "complex_result = await run_complex_pipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline Progress Monitoring\n",
        "\n",
        "Let's check the progress of our pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get pipeline progress\n",
        "progress = complex_pipeline.get_progress()\n",
        "\n",
        "print(\"\ud83d\udcc8 Pipeline Progress:\")\n",
        "print(f\"   Total tasks: {progress['total']}\")\n",
        "print(f\"   Completed: {progress['completed']}\")\n",
        "print(f\"   Running: {progress['running']}\")\n",
        "print(f\"   Pending: {progress['pending']}\")\n",
        "print(f\"   Failed: {progress['failed']}\")\n",
        "print(f\"   Skipped: {progress['skipped']}\")\n",
        "\n",
        "print(f\"\\n\u2705 Pipeline complete: {complex_pipeline.is_complete()}\")\n",
        "print(f\"\u274c Pipeline failed: {complex_pipeline.is_failed()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## State Management and Checkpointing\n",
        "\n",
        "The Orchestrator framework supports state management for long-running workflows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save a checkpoint\n",
        "checkpoint_id = \"complex_pipeline_checkpoint\"\n",
        "execution_id = \"demo_execution_001\"\n",
        "\n",
        "checkpoint_data = {\n",
        "    \"pipeline_id\": complex_pipeline.id,\n",
        "    \"completed_tasks\": complex_pipeline.get_completed_tasks(),\n",
        "    \"progress\": complex_pipeline.get_progress(),\n",
        "    \"metadata\": {\n",
        "        \"execution_time\": \"2024-01-01T12:00:00Z\",\n",
        "        \"user\": \"demo_user\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save checkpoint\n",
        "success = await state_manager.save_checkpoint(\n",
        "    checkpoint_id=checkpoint_id,\n",
        "    execution_id=execution_id,\n",
        "    data=checkpoint_data\n",
        ")\n",
        "\n",
        "print(f\"\u2705 Checkpoint saved: {success}\")\n",
        "\n",
        "# List checkpoints\n",
        "checkpoints = await state_manager.list_checkpoints(execution_id)\n",
        "print(f\"\ud83d\udcc2 Available checkpoints: {len(checkpoints)}\")\n",
        "\n",
        "# Load checkpoint\n",
        "loaded_checkpoint = await state_manager.load_checkpoint(checkpoint_id)\n",
        "if loaded_checkpoint:\n",
        "    print(f\"\ud83d\udce5 Loaded checkpoint data: {loaded_checkpoint['data']['progress']}\")\n",
        "else:\n",
        "    print(\"\u274c Failed to load checkpoint\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Working with Real Models\n",
        "\n",
        "In production, you would use real AI models. Here's how to set them up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of how to use real models (commented out for demo)\n",
        "\n",
        "# from orchestrator.models.openai_model import OpenAIModel\n",
        "# from orchestrator.models.anthropic_model import AnthropicModel\n",
        "\n",
        "# # OpenAI model\n",
        "# openai_model = OpenAIModel(\n",
        "#     name=\"gpt-4\",\n",
        "#     api_key=\"your-openai-api-key\",\n",
        "#     model=\"gpt-4\"\n",
        "# )\n",
        "\n",
        "# # Anthropic model\n",
        "# anthropic_model = AnthropicModel(\n",
        "#     name=\"claude-3-sonnet\",\n",
        "#     api_key=\"your-anthropic-api-key\",\n",
        "#     model=\"claude-3-sonnet-20240229\"\n",
        "# )\n",
        "\n",
        "# # Register with orchestrator\n",
        "# orchestrator.register_model(openai_model)\n",
        "# orchestrator.register_model(anthropic_model)\n",
        "\n",
        "print(\"\ud83d\udca1 In production, configure real models with API keys\")\n",
        "print(\"\ud83d\udca1 Support for OpenAI, Anthropic, Google, and local models\")\n",
        "print(\"\ud83d\udca1 See integration tests for examples of real API usage\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline Serialization\n",
        "\n",
        "Pipelines can be serialized to and from dictionaries for storage or transmission:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Serialize pipeline to dictionary\n",
        "pipeline_dict = complex_pipeline.to_dict()\n",
        "\n",
        "print(\"\ud83d\udcc4 Pipeline serialized to dictionary:\")\n",
        "print(f\"   ID: {pipeline_dict['id']}\")\n",
        "print(f\"   Name: {pipeline_dict['name']}\")\n",
        "print(f\"   Tasks: {len(pipeline_dict['tasks'])}\")\n",
        "print(f\"   Created: {pipeline_dict['created_at']}\")\n",
        "\n",
        "# Recreate pipeline from dictionary\n",
        "recreated_pipeline = Pipeline.from_dict(pipeline_dict)\n",
        "\n",
        "print(f\"\\n\ud83d\udd04 Pipeline recreated: {recreated_pipeline.name}\")\n",
        "print(f\"   Tasks: {len(recreated_pipeline)}\")\n",
        "print(f\"   Same ID: {recreated_pipeline.id == complex_pipeline.id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, you learned:\n",
        "\n",
        "1. **Core Components**: Tasks, Models, Pipelines, and Orchestrator\n",
        "2. **Pipeline Creation**: Building workflows with dependencies\n",
        "3. **Execution**: Running pipelines with mock and real models\n",
        "4. **Monitoring**: Tracking progress and analyzing results\n",
        "5. **State Management**: Checkpointing and resuming workflows\n",
        "6. **Serialization**: Saving and loading pipeline configurations\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Explore the **YAML Configuration** tutorial for declarative pipeline definitions\n",
        "- Learn about **Advanced Model Integration** for real AI providers\n",
        "- Try the **Error Handling and Recovery** tutorial for robust workflows\n",
        "- Check out **Production Deployment** patterns for scaling\n",
        "\n",
        "---\n",
        "\n",
        "**Happy orchestrating! \ud83c\udfb5**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}