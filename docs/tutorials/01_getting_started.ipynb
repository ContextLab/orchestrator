{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Orchestrator Framework\n",
    "\n",
    "This tutorial introduces the core concepts of the Orchestrator framework for building AI/LLM workflows.\n",
    "\n",
    "## What is Orchestrator?\n",
    "\n",
    "Orchestrator is a powerful Python framework for creating, managing, and executing complex AI workflows. It provides:\n",
    "\n",
    "- **Task Management**: Define and organize individual work units\n",
    "- **Pipeline Orchestration**: Create dependency graphs between tasks\n",
    "- **Model Integration**: Work with multiple AI models (OpenAI, Anthropic, local models)\n",
    "- **State Management**: Checkpoint and resume workflows\n",
    "- **YAML Configuration**: Define workflows declaratively\n",
    "\n",
    "## Installation\n",
    "\n",
    "First, make sure you have the orchestrator package installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running from the repository root\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "# Import core components\n",
    "from orchestrator.core.task import Task\n",
    "from orchestrator.core.pipeline import Pipeline\n",
    "from orchestrator.core.model import MockModel, ModelCapabilities\n",
    "from orchestrator.orchestrator import Orchestrator\n",
    "from orchestrator.state.state_manager import InMemoryStateManager\n",
    "\n",
    "print(\"✅ Orchestrator imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Concepts\n",
    "\n",
    "### 1. Tasks\n",
    "\n",
    "Tasks are the fundamental building blocks of workflows. Each task represents a single operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple task\n",
    "task = Task(\n",
    "    id=\"hello_world\",\n",
    "    name=\"Hello World Task\",\n",
    "    action=\"generate\",\n",
    "    parameters={\n",
    "        \"prompt\": \"Say hello to the world\",\n",
    "        \"max_tokens\": 50\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Task ID: {task.id}\")\n",
    "print(f\"Task Name: {task.name}\")\n",
    "print(f\"Task Status: {task.status}\")\n",
    "print(f\"Task Parameters: {task.parameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Models\n",
    "\n",
    "Models represent AI/LLM backends that can execute tasks. Let's create a mock model for demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mock model for testing\n",
    "capabilities = ModelCapabilities(\n",
    "    supported_tasks=[\"generate\", \"analyze\"],\n",
    "    max_tokens=2048,\n",
    "    supports_streaming=True\n",
    ")\n",
    "\n",
    "model = MockModel(\n",
    "    name=\"demo-model\",\n",
    "    provider=\"mock\",\n",
    "    capabilities=capabilities\n",
    ")\n",
    "\n",
    "# Set up some canned responses\n",
    "model.set_response(\"Say hello to the world\", \"Hello, World! 🌍 Welcome to the Orchestrator framework!\")\n",
    "\n",
    "print(f\"Model: {model.name} by {model.provider}\")\n",
    "print(f\"Supported tasks: {model.capabilities.supported_tasks}\")\n",
    "print(f\"Max tokens: {model.capabilities.max_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pipelines\n",
    "\n",
    "Pipelines organize tasks and define their execution order through dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple pipeline\n",
    "pipeline = Pipeline(\n",
    "    id=\"demo_pipeline\",\n",
    "    name=\"Demo Pipeline\",\n",
    "    description=\"A simple demonstration pipeline\"\n",
    ")\n",
    "\n",
    "# Add our task to the pipeline\n",
    "pipeline.add_task(task)\n",
    "\n",
    "print(f\"Pipeline: {pipeline.name}\")\n",
    "print(f\"Number of tasks: {len(pipeline)}\")\n",
    "print(f\"Tasks: {list(pipeline)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Orchestrator\n",
    "\n",
    "The Orchestrator coordinates execution of pipelines using models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an orchestrator with in-memory state management\n",
    "state_manager = InMemoryStateManager()\n",
    "orchestrator = Orchestrator(state_manager=state_manager)\n",
    "\n",
    "# Register our model\n",
    "orchestrator.register_model(model)\n",
    "\n",
    "print(f\"Orchestrator created with {len(orchestrator.models)} model(s)\")\n",
    "print(f\"Available models: {list(orchestrator.models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Your First Pipeline\n",
    "\n",
    "Now let's execute our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def run_pipeline():\n",
    "    \"\"\"Execute the demo pipeline.\"\"\"\n",
    "    result = await orchestrator.execute_pipeline(pipeline)\n",
    "    return result\n",
    "\n",
    "# Run the pipeline\n",
    "result = await run_pipeline()\n",
    "\n",
    "print(f\"Pipeline execution result: {result}\")\n",
    "print(f\"Task status: {task.status}\")\n",
    "print(f\"Task result: {task.result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Multi-Task Pipeline\n",
    "\n",
    "Let's create a more complex pipeline with multiple tasks and dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complex pipeline\n",
    "complex_pipeline = Pipeline(\n",
    "    id=\"analysis_pipeline\",\n",
    "    name=\"Text Analysis Pipeline\",\n",
    "    description=\"Analyze text through multiple steps\"\n",
    ")\n",
    "\n",
    "# Task 1: Generate content\n",
    "generate_task = Task(\n",
    "    id=\"generate_content\",\n",
    "    name=\"Generate Content\",\n",
    "    action=\"generate\",\n",
    "    parameters={\n",
    "        \"prompt\": \"Write a short story about a robot learning to paint\",\n",
    "        \"max_tokens\": 200\n",
    "    }\n",
    ")\n",
    "\n",
    "# Task 2: Analyze sentiment (depends on task 1)\n",
    "sentiment_task = Task(\n",
    "    id=\"analyze_sentiment\",\n",
    "    name=\"Analyze Sentiment\",\n",
    "    action=\"analyze\",\n",
    "    parameters={\n",
    "        \"prompt\": \"Analyze the sentiment of this text: {generate_content.result}\",\n",
    "        \"analysis_type\": \"sentiment\"\n",
    "    },\n",
    "    dependencies=[\"generate_content\"]\n",
    ")\n",
    "\n",
    "# Task 3: Extract themes (depends on task 1)\n",
    "theme_task = Task(\n",
    "    id=\"extract_themes\",\n",
    "    name=\"Extract Themes\",\n",
    "    action=\"analyze\",\n",
    "    parameters={\n",
    "        \"prompt\": \"Extract the main themes from this text: {generate_content.result}\",\n",
    "        \"analysis_type\": \"themes\"\n",
    "    },\n",
    "    dependencies=[\"generate_content\"]\n",
    ")\n",
    "\n",
    "# Task 4: Summarize analysis (depends on tasks 2 and 3)\n",
    "summary_task = Task(\n",
    "    id=\"summarize_analysis\",\n",
    "    name=\"Summarize Analysis\",\n",
    "    action=\"generate\",\n",
    "    parameters={\n",
    "        \"prompt\": \"Summarize this analysis: Sentiment: {analyze_sentiment.result}, Themes: {extract_themes.result}\",\n",
    "        \"max_tokens\": 100\n",
    "    },\n",
    "    dependencies=[\"analyze_sentiment\", \"extract_themes\"]\n",
    ")\n",
    "\n",
    "# Add tasks to pipeline\n",
    "for task in [generate_task, sentiment_task, theme_task, summary_task]:\n",
    "    complex_pipeline.add_task(task)\n",
    "\n",
    "print(f\"Complex pipeline created with {len(complex_pipeline)} tasks\")\n",
    "print(f\"Tasks: {list(complex_pipeline)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the execution order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the execution order\n",
    "execution_order = complex_pipeline.get_execution_order()\n",
    "\n",
    "print(\"Execution order (parallel groups):\")\n",
    "for i, level in enumerate(execution_order):\n",
    "    print(f\"  Level {i+1}: {level}\")\n",
    "\n",
    "# Get the critical path\n",
    "critical_path = complex_pipeline.get_critical_path()\n",
    "print(f\"\\nCritical path: {' -> '.join(critical_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up responses for our mock model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up canned responses for the complex pipeline\n",
    "model.set_response(\n",
    "    \"Write a short story about a robot learning to paint\",\n",
    "    \"ARIA-7 was a maintenance robot who discovered an abandoned art studio. \"\n",
    "    \"Fascinated by the colorful canvases, ARIA-7 began experimenting with brushes and paint. \"\n",
    "    \"Though her first attempts were chaotic splatters, she persisted. Eventually, ARIA-7 \"\n",
    "    \"created beautiful abstract paintings that captured the essence of mechanical precision \"\n",
    "    \"meeting creative expression. Her art became a bridge between the digital and analog worlds.\"\n",
    ")\n",
    "\n",
    "model.set_response(\n",
    "    \"Analyze the sentiment of this text\",\n",
    "    \"The sentiment is predominantly positive and uplifting. The text conveys themes of \"\n",
    "    \"discovery, perseverance, growth, and ultimate success. There's an inspiring tone \"\n",
    "    \"about overcoming initial failures and finding beauty in unexpected places.\"\n",
    ")\n",
    "\n",
    "model.set_response(\n",
    "    \"Extract the main themes from this text\",\n",
    "    \"Main themes include: 1) Self-discovery and growth, 2) Art as a form of expression, \"\n",
    "    \"3) Persistence in the face of initial failure, 4) The intersection of technology and creativity, \"\n",
    "    \"5) Finding purpose beyond original design, 6) Bridging different worlds or perspectives.\"\n",
    ")\n",
    "\n",
    "model.set_response(\n",
    "    \"Summarize this analysis\",\n",
    "    \"This story presents a heartwarming narrative with positive sentiment, centered on themes \"\n",
    "    \"of personal growth, creative expression, and the beautiful intersection of technology and art. \"\n",
    "    \"It's an inspiring tale of persistence and self-discovery.\"\n",
    ")\n",
    "\n",
    "print(\"✅ Mock responses configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's execute the complex pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_complex_pipeline():\n",
    "    \"\"\"Execute the complex analysis pipeline.\"\"\"\n",
    "    print(\"🚀 Starting complex pipeline execution...\\n\")\n",
    "    \n",
    "    # Execute the pipeline\n",
    "    result = await orchestrator.execute_pipeline(complex_pipeline)\n",
    "    \n",
    "    print(f\"\\n✅ Pipeline execution completed with result: {result}\\n\")\n",
    "    \n",
    "    # Show results for each task\n",
    "    print(\"📊 Task Results:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for task_id in execution_order[0] + execution_order[1] + execution_order[2]:\n",
    "        task = complex_pipeline.get_task(task_id)\n",
    "        print(f\"\\n🔸 {task.name} ({task.id})\")\n",
    "        print(f\"   Status: {task.status}\")\n",
    "        if task.result:\n",
    "            # Truncate long results for display\n",
    "            result_text = task.result[:200] + \"...\" if len(task.result) > 200 else task.result\n",
    "            print(f\"   Result: {result_text}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Execute the complex pipeline\n",
    "complex_result = await run_complex_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Progress Monitoring\n",
    "\n",
    "Let's check the progress of our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pipeline progress\n",
    "progress = complex_pipeline.get_progress()\n",
    "\n",
    "print(\"📈 Pipeline Progress:\")\n",
    "print(f\"   Total tasks: {progress['total']}\")\n",
    "print(f\"   Completed: {progress['completed']}\")\n",
    "print(f\"   Running: {progress['running']}\")\n",
    "print(f\"   Pending: {progress['pending']}\")\n",
    "print(f\"   Failed: {progress['failed']}\")\n",
    "print(f\"   Skipped: {progress['skipped']}\")\n",
    "\n",
    "print(f\"\\n✅ Pipeline complete: {complex_pipeline.is_complete()}\")\n",
    "print(f\"❌ Pipeline failed: {complex_pipeline.is_failed()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Management and Checkpointing\n",
    "\n",
    "The Orchestrator framework supports state management for long-running workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a checkpoint\n",
    "checkpoint_id = \"complex_pipeline_checkpoint\"\n",
    "execution_id = \"demo_execution_001\"\n",
    "\n",
    "checkpoint_data = {\n",
    "    \"pipeline_id\": complex_pipeline.id,\n",
    "    \"completed_tasks\": complex_pipeline.get_completed_tasks(),\n",
    "    \"progress\": complex_pipeline.get_progress(),\n",
    "    \"metadata\": {\n",
    "        \"execution_time\": \"2024-01-01T12:00:00Z\",\n",
    "        \"user\": \"demo_user\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save checkpoint\n",
    "success = await state_manager.save_checkpoint(\n",
    "    checkpoint_id=checkpoint_id,\n",
    "    execution_id=execution_id,\n",
    "    data=checkpoint_data\n",
    ")\n",
    "\n",
    "print(f\"✅ Checkpoint saved: {success}\")\n",
    "\n",
    "# List checkpoints\n",
    "checkpoints = await state_manager.list_checkpoints(execution_id)\n",
    "print(f\"📂 Available checkpoints: {len(checkpoints)}\")\n",
    "\n",
    "# Load checkpoint\n",
    "loaded_checkpoint = await state_manager.load_checkpoint(checkpoint_id)\n",
    "if loaded_checkpoint:\n",
    "    print(f\"📥 Loaded checkpoint data: {loaded_checkpoint['data']['progress']}\")\n",
    "else:\n",
    "    print(\"❌ Failed to load checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Real Models\n",
    "\n",
    "In production, you would use real AI models. Here's how to set them up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to use real models (commented out for demo)\n",
    "\n",
    "# from orchestrator.models.openai_model import OpenAIModel\n",
    "# from orchestrator.models.anthropic_model import AnthropicModel\n",
    "\n",
    "# # OpenAI model\n",
    "# openai_model = OpenAIModel(\n",
    "#     name=\"gpt-4\",\n",
    "#     api_key=\"your-openai-api-key\",\n",
    "#     model=\"gpt-4\"\n",
    "# )\n",
    "\n",
    "# # Anthropic model\n",
    "# anthropic_model = AnthropicModel(\n",
    "#     name=\"claude-3-sonnet\",\n",
    "#     api_key=\"your-anthropic-api-key\",\n",
    "#     model=\"claude-3-sonnet-20240229\"\n",
    "# )\n",
    "\n",
    "# # Register with orchestrator\n",
    "# orchestrator.register_model(openai_model)\n",
    "# orchestrator.register_model(anthropic_model)\n",
    "\n",
    "print(\"💡 In production, configure real models with API keys\")\n",
    "print(\"💡 Support for OpenAI, Anthropic, Google, and local models\")\n",
    "print(\"💡 See integration tests for examples of real API usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Serialization\n",
    "\n",
    "Pipelines can be serialized to and from dictionaries for storage or transmission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize pipeline to dictionary\n",
    "pipeline_dict = complex_pipeline.to_dict()\n",
    "\n",
    "print(\"📄 Pipeline serialized to dictionary:\")\n",
    "print(f\"   ID: {pipeline_dict['id']}\")\n",
    "print(f\"   Name: {pipeline_dict['name']}\")\n",
    "print(f\"   Tasks: {len(pipeline_dict['tasks'])}\")\n",
    "print(f\"   Created: {pipeline_dict['created_at']}\")\n",
    "\n",
    "# Recreate pipeline from dictionary\n",
    "recreated_pipeline = Pipeline.from_dict(pipeline_dict)\n",
    "\n",
    "print(f\"\\n🔄 Pipeline recreated: {recreated_pipeline.name}\")\n",
    "print(f\"   Tasks: {len(recreated_pipeline)}\")\n",
    "print(f\"   Same ID: {recreated_pipeline.id == complex_pipeline.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **Core Components**: Tasks, Models, Pipelines, and Orchestrator\n",
    "2. **Pipeline Creation**: Building workflows with dependencies\n",
    "3. **Execution**: Running pipelines with mock and real models\n",
    "4. **Monitoring**: Tracking progress and analyzing results\n",
    "5. **State Management**: Checkpointing and resuming workflows\n",
    "6. **Serialization**: Saving and loading pipeline configurations\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore the **YAML Configuration** tutorial for declarative pipeline definitions\n",
    "- Learn about **Advanced Model Integration** for real AI providers\n",
    "- Try the **Error Handling and Recovery** tutorial for robust workflows\n",
    "- Check out **Production Deployment** patterns for scaling\n",
    "\n",
    "---\n",
    "\n",
    "**Happy orchestrating! 🎵**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}