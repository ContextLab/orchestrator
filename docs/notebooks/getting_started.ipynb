{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Orchestrator\n",
    "\n",
    "This notebook demonstrates the basic features of the Orchestrator framework with interactive examples.\n",
    "\n",
    "## Installation\n",
    "\n",
    "First, make sure you have Orchestrator installed:\n",
    "\n",
    "```bash\n",
    "pip install orchestrator-ai\n",
    "```\n",
    "\n",
    "Or clone and install from source:\n",
    "```bash\n",
    "git clone https://github.com/ContextLab/orchestrator\n",
    "cd orchestrator\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's start by importing the necessary modules and setting up our API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Import Orchestrator\n",
    "from orchestrator import Orchestrator, init_models\n",
    "\n",
    "# Set API keys (replace with your actual keys)\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-openai-key'\n",
    "# os.environ['ANTHROPIC_API_KEY'] = 'your-anthropic-key'\n",
    "\n",
    "# Check if API keys are set\n",
    "has_openai = bool(os.getenv('OPENAI_API_KEY'))\n",
    "has_anthropic = bool(os.getenv('ANTHROPIC_API_KEY'))\n",
    "\n",
    "print(f\"OpenAI API Key: {'‚úÖ Set' if has_openai else '‚ùå Not set'}\")\n",
    "print(f\"Anthropic API Key: {'‚úÖ Set' if has_anthropic else '‚ùå Not set'}\")\n",
    "\n",
    "if not (has_openai or has_anthropic):\n",
    "    print(\"\\n‚ö†Ô∏è Warning: You'll need to set at least one API key to run AI-powered examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Orchestrator\n",
    "\n",
    "Let's create an Orchestrator instance with default models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models and orchestrator\n",
    "print(\"Initializing models...\")\n",
    "model_registry = init_models()\n",
    "orchestrator = Orchestrator(model_registry=model_registry)\n",
    "\n",
    "print(f\"‚úÖ Orchestrator initialized with {len(model_registry.models)} models\")\n",
    "print(f\"Available models: {list(model_registry.models.keys())[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple Report Generation\n",
    "\n",
    "Let's start with a simple pipeline that generates a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_pipeline = \"\"\"\n",
    "name: simple-report\n",
    "description: Generate a simple report\n",
    "\n",
    "steps:\n",
    "  - id: create_report\n",
    "    tool: report-generator\n",
    "    action: generate\n",
    "    parameters:\n",
    "      title: \"My First Orchestrator Report\"\n",
    "      format: \"markdown\"\n",
    "      content: |\n",
    "        # Welcome to Orchestrator!\n",
    "        \n",
    "        This report was generated using the Orchestrator framework.\n",
    "        \n",
    "        ## Features:\n",
    "        - YAML-based pipeline definitions\n",
    "        - AI-powered task execution\n",
    "        - Parallel processing\n",
    "        - Intelligent model routing\n",
    "        \n",
    "        Generated at: {{ current_date }}\n",
    "\"\"\"\n",
    "\n",
    "# Execute the pipeline\n",
    "result = await orchestrator.execute_yaml(simple_pipeline)\n",
    "print(\"‚úÖ Pipeline completed!\")\n",
    "print(f\"Report content:\\n{result['create_report']['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: File Operations\n",
    "\n",
    "Let's create a pipeline that works with files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pipeline = \"\"\"\n",
    "name: file-operations\n",
    "description: Demonstrate file operations\n",
    "\n",
    "steps:\n",
    "  - id: create_file\n",
    "    tool: filesystem\n",
    "    action: write\n",
    "    parameters:\n",
    "      path: \"/tmp/orchestrator_demo.txt\"\n",
    "      content: |\n",
    "        This is a demo file created by Orchestrator.\n",
    "        It contains sample data for processing.\n",
    "        \n",
    "        Data points:\n",
    "        - Point 1: 42\n",
    "        - Point 2: 84\n",
    "        - Point 3: 126\n",
    "      mode: \"w\"\n",
    "      \n",
    "  - id: read_file\n",
    "    tool: filesystem\n",
    "    action: read\n",
    "    parameters:\n",
    "      path: \"/tmp/orchestrator_demo.txt\"\n",
    "      \n",
    "  - id: check_exists\n",
    "    tool: filesystem\n",
    "    action: exists\n",
    "    parameters:\n",
    "      path: \"/tmp/orchestrator_demo.txt\"\n",
    "\"\"\"\n",
    "\n",
    "# Execute the pipeline\n",
    "result = await orchestrator.execute_yaml(file_pipeline)\n",
    "print(\"‚úÖ File operations completed!\")\n",
    "print(f\"File exists: {result['check_exists']['exists']}\")\n",
    "print(f\"File content:\\n{result['read_file']['content']}\")\n",
    "\n",
    "# Clean up\n",
    "if os.path.exists(\"/tmp/orchestrator_demo.txt\"):\n",
    "    os.unlink(\"/tmp/orchestrator_demo.txt\")\n",
    "    print(\"‚úÖ Cleanup completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: AUTO Tags (AI-Powered)\n",
    "\n",
    "This example demonstrates AUTO tags that use AI to make dynamic decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_tags_pipeline = \"\"\"\n",
    "name: auto-tags-demo\n",
    "description: Demonstrate AUTO tags for dynamic decisions\n",
    "\n",
    "inputs:\n",
    "  user_query: \"I need help creating a presentation about machine learning\"\n",
    "\n",
    "steps:\n",
    "  - id: analyze_request\n",
    "    tool: llm-generate\n",
    "    action: generate\n",
    "    parameters:\n",
    "      prompt: \"User request: {{ user_query }}\"\n",
    "      task_type: <AUTO>What type of task is this? Choose: 'presentation', 'analysis', 'coding', 'research'</AUTO>\n",
    "      urgency: <AUTO>How urgent is this request? Choose: 'low', 'medium', 'high'</AUTO>\n",
    "      \n",
    "  - id: create_outline\n",
    "    tool: llm-generate\n",
    "    action: generate\n",
    "    parameters:\n",
    "      prompt: |\n",
    "        Create an outline for: {{ user_query }}\n",
    "        Task type: {{ analyze_request.task_type }}\n",
    "        Urgency: {{ analyze_request.urgency }}\n",
    "      detail_level: <AUTO>Given the urgency level, how detailed should this be? Choose: 'brief', 'standard', 'comprehensive'</AUTO>\n",
    "      \n",
    "  - id: generate_report\n",
    "    tool: report-generator\n",
    "    action: generate\n",
    "    parameters:\n",
    "      title: \"AI-Generated Task Response\"\n",
    "      format: <AUTO>What's the best format for a {{ analyze_request.task_type }} deliverable? Choose: 'markdown', 'html', 'pdf'</AUTO>\n",
    "      content: |\n",
    "        # Task Analysis\n",
    "        \n",
    "        **Original Request:** {{ user_query }}\n",
    "        \n",
    "        **Task Type:** {{ analyze_request.task_type }}\n",
    "        **Urgency:** {{ analyze_request.urgency }}\n",
    "        **Detail Level:** {{ create_outline.detail_level }}\n",
    "        \n",
    "        ## Generated Outline\n",
    "        {{ create_outline.result }}\n",
    "        \n",
    "        ---\n",
    "        *Generated by Orchestrator AUTO tags*\n",
    "\"\"\"\n",
    "\n",
    "# Execute only if we have API access\n",
    "if has_openai or has_anthropic:\n",
    "    result = await orchestrator.execute_yaml(auto_tags_pipeline, {\n",
    "        \"user_query\": \"I need help creating a presentation about machine learning\"\n",
    "    })\n",
    "    print(\"‚úÖ AUTO tags pipeline completed!\")\n",
    "    print(f\"Task type identified: {result['analyze_request']['task_type']}\")\n",
    "    print(f\"Urgency level: {result['analyze_request']['urgency']}\")\n",
    "    print(f\"Detail level chosen: {result['create_outline']['detail_level']}\")\n",
    "    print(f\"Output format: {result['generate_report']['format']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping AUTO tags example - requires API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Data Processing\n",
    "\n",
    "Let's process some sample data using the data processing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample CSV data\n",
    "sample_csv = \"\"\"name,age,city,salary\n",
    "Alice,28,New York,75000\n",
    "Bob,35,San Francisco,95000\n",
    "Carol,42,Chicago,65000\n",
    "David,29,Seattle,80000\n",
    "Eve,31,Boston,70000\"\"\"\n",
    "\n",
    "# Write sample data to file\n",
    "with open(\"/tmp/sample_data.csv\", \"w\") as f:\n",
    "    f.write(sample_csv)\n",
    "\n",
    "data_pipeline = \"\"\"\n",
    "name: data-processing-demo\n",
    "description: Process CSV data\n",
    "\n",
    "steps:\n",
    "  - id: read_csv\n",
    "    tool: filesystem\n",
    "    action: read\n",
    "    parameters:\n",
    "      path: \"/tmp/sample_data.csv\"\n",
    "      \n",
    "  - id: transform_data\n",
    "    tool: data-processing\n",
    "    action: transform\n",
    "    parameters:\n",
    "      input_data: \"{{ read_csv.content }}\"\n",
    "      input_format: \"csv\"\n",
    "      output_format: \"json\"\n",
    "      operations:\n",
    "        - type: filter\n",
    "          condition: \"age > 30\"\n",
    "        - type: sort\n",
    "          by: \"salary\"\n",
    "          ascending: false\n",
    "          \n",
    "  - id: create_summary\n",
    "    tool: report-generator\n",
    "    action: generate\n",
    "    parameters:\n",
    "      title: \"Data Processing Summary\"\n",
    "      format: \"markdown\"\n",
    "      content: |\n",
    "        # Data Processing Results\n",
    "        \n",
    "        ## Filtered Data (Age > 30, sorted by salary)\n",
    "        \n",
    "        {% for person in transform_data.result %}\n",
    "        - **{{ person.name }}**: Age {{ person.age }}, {{ person.city }}, ${{ person.salary }}\n",
    "        {% endfor %}\n",
    "        \n",
    "        Total records processed: {{ transform_data.result | length }}\n",
    "\"\"\"\n",
    "\n",
    "# Execute the pipeline\n",
    "result = await orchestrator.execute_yaml(data_pipeline)\n",
    "print(\"‚úÖ Data processing completed!\")\n",
    "print(f\"Processed {len(result['transform_data']['result'])} records\")\n",
    "print(\"\\nSummary report:\")\n",
    "print(result['create_summary']['content'])\n",
    "\n",
    "# Clean up\n",
    "if os.path.exists(\"/tmp/sample_data.csv\"):\n",
    "    os.unlink(\"/tmp/sample_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Parallel Execution\n",
    "\n",
    "This example shows how Orchestrator can run independent tasks in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "parallel_pipeline = \"\"\"\n",
    "name: parallel-demo\n",
    "description: Demonstrate parallel task execution\n",
    "\n",
    "steps:\n",
    "  # These three tasks will run in parallel (no dependencies)\n",
    "  - id: task_a\n",
    "    tool: terminal\n",
    "    action: execute\n",
    "    parameters:\n",
    "      command: \"echo 'Task A completed' && sleep 2\"\n",
    "      timeout: 10\n",
    "      \n",
    "  - id: task_b\n",
    "    tool: terminal\n",
    "    action: execute\n",
    "    parameters:\n",
    "      command: \"echo 'Task B completed' && sleep 1\"\n",
    "      timeout: 10\n",
    "      \n",
    "  - id: task_c\n",
    "    tool: terminal\n",
    "    action: execute\n",
    "    parameters:\n",
    "      command: \"echo 'Task C completed' && sleep 3\"\n",
    "      timeout: 10\n",
    "  \n",
    "  # This task depends on all previous tasks\n",
    "  - id: combine_results\n",
    "    tool: report-generator\n",
    "    action: generate\n",
    "    dependencies: [\"task_a\", \"task_b\", \"task_c\"]\n",
    "    parameters:\n",
    "      title: \"Parallel Execution Results\"\n",
    "      format: \"markdown\"\n",
    "      content: |\n",
    "        # Parallel Task Results\n",
    "        \n",
    "        ## Task Outputs:\n",
    "        - Task A: {{ task_a.stdout }}\n",
    "        - Task B: {{ task_b.stdout }}\n",
    "        - Task C: {{ task_c.stdout }}\n",
    "        \n",
    "        All tasks completed successfully in parallel!\n",
    "\"\"\"\n",
    "\n",
    "# Time the execution\n",
    "start_time = time.time()\n",
    "result = await orchestrator.execute_yaml(parallel_pipeline)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"‚úÖ Parallel execution completed in {end_time - start_time:.1f} seconds\")\n",
    "print(\"(Tasks ran in parallel - total time should be close to the longest task)\")\n",
    "print(\"\\nCombined results:\")\n",
    "print(result['combine_results']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Error Handling\n",
    "\n",
    "Let's see how Orchestrator handles errors and continues execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_handling_pipeline = \"\"\"\n",
    "name: error-handling-demo\n",
    "description: Demonstrate error handling\n",
    "\n",
    "steps:\n",
    "  - id: successful_task\n",
    "    tool: terminal\n",
    "    action: execute\n",
    "    parameters:\n",
    "      command: \"echo 'This task succeeds'\"\n",
    "      \n",
    "  - id: failing_task\n",
    "    tool: filesystem\n",
    "    action: read\n",
    "    parameters:\n",
    "      path: \"/nonexistent/file.txt\"  # This will fail\n",
    "    on_failure: continue  # Continue pipeline even if this fails\n",
    "    \n",
    "  - id: recovery_task\n",
    "    tool: filesystem\n",
    "    action: write\n",
    "    condition: \"{{ failing_task.status == 'failed' }}\"  # Only run if previous failed\n",
    "    parameters:\n",
    "      path: \"/tmp/recovery.txt\"\n",
    "      content: \"Recovery action executed because previous task failed\"\n",
    "      \n",
    "  - id: final_report\n",
    "    tool: report-generator\n",
    "    action: generate\n",
    "    dependencies: [\"successful_task\"]  # Only depends on successful task\n",
    "    parameters:\n",
    "      title: \"Error Handling Report\"\n",
    "      format: \"markdown\"\n",
    "      content: |\n",
    "        # Error Handling Results\n",
    "        \n",
    "        - Successful task: ‚úÖ {{ successful_task.stdout }}\n",
    "        - Failing task: ‚ùå {{ failing_task.status }}\n",
    "        - Recovery task: {% if recovery_task %}‚úÖ Executed{% else %}‚è≠Ô∏è Skipped{% endif %}\n",
    "        \n",
    "        Pipeline continued despite the failing task!\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = await orchestrator.execute_yaml(error_handling_pipeline)\n",
    "    print(\"‚úÖ Pipeline completed with error handling\")\n",
    "    print(\"\\nFinal report:\")\n",
    "    print(result['final_report']['content'])\n",
    "    \n",
    "    # Check if recovery file was created\n",
    "    if os.path.exists(\"/tmp/recovery.txt\"):\n",
    "        with open(\"/tmp/recovery.txt\", \"r\") as f:\n",
    "            print(f\"\\nRecovery file content: {f.read()}\")\n",
    "        os.unlink(\"/tmp/recovery.txt\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Pipeline failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Status and Monitoring\n",
    "\n",
    "Orchestrator provides ways to monitor pipeline execution and get metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance metrics\n",
    "metrics = await orchestrator.get_performance_metrics()\n",
    "\n",
    "print(\"üìä Orchestrator Performance Metrics:\")\n",
    "print(f\"Total executions: {metrics['total_executions']}\")\n",
    "print(f\"Successful executions: {metrics['successful_executions']}\")\n",
    "print(f\"Failed executions: {metrics['failed_executions']}\")\n",
    "print(f\"Average execution time: {metrics['average_execution_time']:.2f}s\")\n",
    "print(f\"Running pipelines: {metrics['running_pipelines']}\")\n",
    "\n",
    "# Get execution history\n",
    "history = orchestrator.get_execution_history(limit=5)\n",
    "print(f\"\\nüìú Recent Executions ({len(history)} shown):\")\n",
    "for record in history:\n",
    "    status_emoji = \"‚úÖ\" if record['status'] == 'completed' else \"‚ùå\"\n",
    "    print(f\"{status_emoji} {record['pipeline_id']} - {record['status']} ({record.get('execution_time', 0):.1f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Check\n",
    "\n",
    "Let's check the health of all Orchestrator components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform health check\n",
    "health = await orchestrator.health_check()\n",
    "\n",
    "print(\"üè• System Health Check:\")\n",
    "for component, status in health.items():\n",
    "    if status == 'healthy':\n",
    "        emoji = \"‚úÖ\"\n",
    "    elif status == 'warning':\n",
    "        emoji = \"‚ö†Ô∏è\"\n",
    "    else:\n",
    "        emoji = \"‚ùå\"\n",
    "    print(f\"{emoji} {component}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've seen the basics of Orchestrator, here are some next steps to explore:\n",
    "\n",
    "1. **Explore Examples**: Check out the `examples/` directory for more complex workflows\n",
    "2. **Read the Documentation**: Visit the `docs/` directory for comprehensive guides\n",
    "3. **Create Custom Tools**: Learn how to build your own tools for specific needs\n",
    "4. **Advanced Features**: Explore model routing, AUTO tags, and parallel processing\n",
    "5. **Integration**: Connect Orchestrator with your existing systems\n",
    "\n",
    "### Useful Links\n",
    "\n",
    "- [Documentation](../README.md)\n",
    "- [Examples](../../examples/)\n",
    "- [API Reference](../reference/api_reference.md)\n",
    "- [Tool Catalog](../reference/tool_catalog.md)\n",
    "- [GitHub Repository](https://github.com/ContextLab/orchestrator)\n",
    "\n",
    "Happy orchestrating! üéº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up (optional)\n",
    "print(\"üßπ Cleaning up...\")\n",
    "orchestrator.clear_execution_history()\n",
    "print(\"‚úÖ Cleanup completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}