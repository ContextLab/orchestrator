Carefully review the pipeline referenced in issue #$ARGUMENTS. Cross reference every line with the relevant parts of the toolbox. Pay special attention to explicit errors (e.g., misnaming tools or models, misnaming or misreferencing files or external resources, referencing steps that don't exist yet, missing dependencies, incorrect formatting, syntax errors, and so on) and logic issues (e.g., missing steps, incorrect ordering, inefficiencies, hard-coding values that should be computed on-the-fly, and so on).

If there are any existing outputs (in the examples/outputs/<pipeline name> folder), examine those as well, to get a sense of potential issues. In the output files, pay special attention to bad formatting, unrendered placeholders, inclusion of "conversational" text, or any other unexpected issues.  Note that the existing outputs may have been generated before changes to the toolbox or current version of this pipeline, so you should also run the pipeline again (and examine the outputs and stack trace via the checkpoints in the checkpoints/ folder) to get a sense of the current status. However, also be on the lookout for stochastic issues that may not crop up in every run-- so even if *this* run of the pipeline works, errors in the existing outputs may still be diagnostic (and at minimum need to be looked into further).  Remember that you should use the run_pipeline.py script to execute the pipeline.  Use the -o flag to specify that the outputs should go in the examples/outputs/<pipeline name> folder.

In addition to identiying pipeline-specific issues, also carefully read the existing issue text, including *ALL* comments.

Once you do all of this, think carefully about what needs to be changed. Pay special attention to whether those changes should be made to the pipeline (i.e., errors in the pipeline, unexpected or poor performance that could be fixed using prompt changes or updates to the logic, or other pipeline-specific issues) and/or the toolbox (i.e., more fundamental errors like missing tools, placeholder code, mocks or simulations, incorrect or incomplete implementations, non-working code, bad or incomplete logic, and so on). 

If you notice minor problems, like syntax errors that you know how to fix, then make those fixes and re-run the pipeline.

Then write out a detailed update containing a comprehensive description of everything that needs to be done in order to bring the pipeline up to 100% functionality, producing high-quality outputs. Post the update as a comment on the issue (also noting any changes you made).  We'll use the update to (a) get a sense of the current status of this pipeline and (b) draft a detailed implementation plan, based on that status. For now, just focus on the update itself so that we have a complete and accurate sense of the current status. The update should have both breadth (covering *ALL* relevant issues) and depth (careful checking of the complete status, using evidence from actual runs and actual files to verify accuracy).

Do NOT comment out or remove sections of the pipeline, or skip a step because something isn't implemented yet, or because there's a missing dependency. We need to include implementations of those missing things (or installation of the missing packages/tools/resources) in the update you post.
