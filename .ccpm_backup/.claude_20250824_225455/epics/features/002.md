---
name: Analysis: Supporting Original Research Report Pipeline Syntax
status: active
created: 2025-08-03T13:53:36Z
updated: 2025-08-06T03:19:33Z
github: https://github.com/ContextLab/orchestrator/issues/186
imported: true
labels: enhancement
---

# Analysis: Supporting Original Research Report Pipeline Syntax

**GitHub Issue:** [#186](https://github.com/ContextLab/orchestrator/issues/186)
**Status:** OPEN
**Labels:** enhancement

## Description

# Analysis: Original Research Report Pipeline

## Overview
This analysis examines the original `original_research_report_pipeline.yaml` that served as inspiration for the Orchestrator framework. We'll identify syntax errors, assess compatibility with the current implementation, and propose an implementation plan.

## 1. Syntax Errors (To Fix Without Changing Functionality)

### Line 4-5: Invalid input syntax
```yaml
# Current:
- topic: {report-topic}
- instructions: {report-instructions}

# Should be:
  topic: 
    description: "Topic for the research report"
    required: true
  instructions:
    description: "Additional instructions for report generation"
    required: true
```

### Line 9: Invalid template syntax
```yaml
# Current:
- tex: {pdf}[:-3] + '.tex'

# Should be:
  tex: "{{ pdf[:-3] }}.tex"
```

### Line 11: Missing steps key
```yaml
# Current:
pipeline:

# Should be:
steps:
```

### Line 12-19: Invalid step structure
```yaml
# Current:
- web-search:
  - action: ...
  - tool: ...

# Should be:
  - id: web-search
    action: ...
    tool: headless-browser
```

### Line 47: Missing colon after "action"
```yaml
# Current:
- action <AUTO>...

# Should be:
  action: <AUTO>...
```

### Line 83: Invalid terminal command syntax
```yaml
# Current:
- action: "!pandoc -o {location} {quality-check-full-report}"

# Should be:
  action: execute_command
  parameters:
    command: "pandoc -o {{ location }} {{ quality-check-full-report.result }}"
```

## 2. What Should Work vs. What Needs Implementation

### Currently Supported ✅
1. **Basic pipeline structure** - id, inputs, outputs, steps
2. **AUTO tags** - For ambiguity resolution
3. **Dependencies** - `depends-on` between steps
4. **Template variables** - `{{ variable }}` syntax
5. **Conditional execution** - `if` conditions
6. **Control flow** - `goto` for dynamic routing
7. **For loops** - `for_each` over lists
8. **Model requirements** - Basic model specification

### Needs Implementation ❌
1. **Nested actions** (`action-loop`, `create-parallel-queue`)
2. **Loop conditions** (`until` with AUTO tags)
3. **File references** (`<<prompt.md>>` syntax)
4. **Terminal commands** (`!command` syntax)
5. **Dynamic file locations** with template variables
6. **Produces/location** metadata for output tracking
7. **Error handlers** (`on-error` directives)
8. **Item references** (`#item` for current loop item)
9. **Step output references** (`{step-name}` syntax)
10. **Complex model requirements** (min-size, expertise)
11. **Parallel queues** with dynamic task generation

## 3. Implementation Plan

### Phase 1: Core Features (1-2 weeks)
1. **Fix parser** to handle the pipeline syntax properly
2. **Add produces/location metadata** to Task model
3. **Implement file reference loader** for `<<file.md>>` syntax
4. **Add terminal/command execution action**
5. **Support dynamic file paths** in parameters

### Phase 2: Loop Constructs (2-3 weeks)
1. **Implement action-loop** with sequential execution
2. **Add until conditions** with AUTO tag support
3. **Implement item references** (`#item`) in loop context
4. **Add loop state management** for iterations

### Phase 3: Parallel Execution (2-3 weeks)
1. **Implement create-parallel-queue** action
2. **Add dynamic task generation** from AUTO-resolved lists
3. **Support parallel execution** with max workers
4. **Add queue management** and result aggregation

### Phase 4: Advanced Features (1-2 weeks)
1. **Implement on-error handlers**
2. **Add complex model requirements** matching
3. **Support nested action structures**
4. **Add pipeline validation** for new constructs

## 4. API Changes Required

### Task Model Extensions
```python
class Task:
    # Add new fields
    produces: Optional[str]  # Output type specification
    location: Optional[str]  # Output file location
    on_error: Optional[str]  # Error handler task ID
    
class LoopTask(Task):
    action_loop: List[Dict[str, Any]]  # Nested actions
    until: Optional[str]  # Loop termination condition
    
class ParallelQueueTask(Task):
    on: str  # Expression to generate queue items
    max_parallel: int = 10  # Parallel execution limit
```

### New Action Types
```python
# In action registry
"create-parallel-queue": ParallelQueueAction
"execute_command": TerminalCommandAction
"action-loop": LoopAction
```

### Context Extensions
```python
# Loop context variables
context["$item"] = current_item  # Current loop item
context["$index"] = loop_index   # Current iteration
context["$queue"] = queue_items  # All queue items
```

## 5. Pros and Cons Analysis

### Current Approach
**Pros:**
- Clean separation of concerns
- Type-safe task definitions
- Clear dependency management
- Straightforward execution model
- Easy to debug and trace

**Cons:**
- Limited expressiveness for complex workflows
- No native support for nested actions
- Requires more verbose YAML for simple tasks

### Original Pipeline Approach
**Pros:**
- Extremely expressive and concise
- Natural language-like syntax
- Powerful loop and parallel constructs
- Integrated error handling
- File-centric workflow design

**Cons:**
- Complex parsing requirements
- Harder to validate statically
- Mixing of concerns (actions, tools, locations)
- Non-standard YAML structure
- Difficult to type-check

## 6. Recommendations

### Short Term
1. **Create a compatibility layer** that translates the original syntax to current format
2. **Implement the most critical features** (loops, parallel queues, file references)
3. **Add syntactic sugar** for common patterns while maintaining core structure

### Long Term
1. **Design a DSL** that captures the expressiveness of the original while maintaining type safety
2. **Support both syntaxes** with automatic conversion between them
3. **Build visual pipeline editor** that generates the verbose format from high-level specifications

### Key Insight
The original pipeline represents a **domain-specific language** for AI workflows, while the current implementation is more of a **general-purpose orchestration framework**. The challenge is bridging these two paradigms without losing the benefits of either approach.