# Model configuration for Orchestrator
# This file defines available models and their properties

models:
  # Ollama models (downloaded on first use)
  - source: ollama
    name: deepseek-r1:1.5b
    expertise: 
      - reasoning
      - code
      - math
    size: 1.5b
    
  - source: ollama
    name: deepseek-r1:8b
    expertise: 
      - reasoning
      - code
      - math
    size: 8b
    
  - source: ollama
    name: deepseek-r1:32b
    expertise: 
      - reasoning
      - code
      - math
      - analysis
    size: 32b
    
  - source: ollama
    name: gemma3:1b
    expertise:
      - general
      - fast
      - compact
    size: 1b
    
  - source: ollama
    name: gemma3:4b
    expertise:
      - general
      - reasoning
    size: 4b
    
  - source: ollama
    name: gemma3:12b
    expertise:
      - general
      - reasoning
      - analysis
    size: 12b
    
  - source: ollama
    name: gemma3:27b
    expertise:
      - general
      - reasoning
      - analysis
    size: 27b
    
  - source: ollama
    name: gemma3n:e4b
    expertise:
      - general
      - efficient
    size: 4b
    
  - source: ollama
    name: llama3.1:8b
    expertise:
      - general
      - reasoning
      - multilingual
    size: 8b
    
  - source: ollama
    name: llama3.2:1b
    expertise:
      - general
      - fast
    size: 1b
    
  - source: ollama
    name: llama3.2:3b
    expertise:
      - general
      - fast
    size: 3b
    
  - source: ollama
    name: mistral:7b
    expertise:
      - general
      - code
    size: 7b
    
  - source: ollama
    name: qwen2.5-coder:7b
    expertise:
      - code
      - programming
    size: 7b
    
  - source: ollama
    name: qwen2.5-coder:14b
    expertise:
      - code
      - programming
      - analysis
    size: 14b
    
  - source: ollama
    name: qwen2.5-coder:32b
    expertise:
      - code
      - programming
      - analysis
      - reasoning
    size: 32b

  # HuggingFace models (temporarily disabled for Issue #157 testing)
  # Re-enable after fixing authentication and model compatibility issues
  # - source: huggingface
  #   name: meta-llama/Llama-3.2-11B-Vision-Instruct
  #   ...rest of HuggingFace models commented out for API testing

  # OpenAI models (require OPENAI_API_KEY)
  # GPT-5 Series (Latest - Released Jan 2025)
  - source: openai
    name: gpt-5
    expertise:
      - general
      - reasoning
      - code
      - analysis
      - instruction-following
      - vision
      - multimodal
    size: 2000b  # Estimated
    
  - source: openai
    name: gpt-5-mini
    expertise:
      - general
      - fast
      - efficient
      - reasoning
    size: 100b  # Estimated
    
  - source: openai
    name: gpt-5-nano
    expertise:
      - fast
      - compact
      - efficient
    size: 10b  # Estimated

  # Anthropic models (require ANTHROPIC_API_KEY)
  # Claude 4 Series
  - source: anthropic
    name: claude-opus-4-20250514
    expertise:
      - general
      - reasoning
      - analysis
      - code
      - complex-tasks
    size: 2500b  # Estimated
    
  - source: anthropic
    name: claude-sonnet-4-20250514
    expertise:
      - general
      - reasoning
      - efficient
    size: 600b  # Estimated
    
  # Claude 3.x Series (Deprecated - use 4th generation models instead)
  # - source: anthropic
  #   name: claude-3-7-sonnet-20250219
  #   expertise:
  #     - general
  #     - reasoning
  #     - analysis
  #     - extended-thinking
  #   size: 400b  # Estimated
  #   
  # - source: anthropic
  #   name: claude-3-5-sonnet-20241022
  #   expertise:
  #     - general
  #     - fast
  #     - balanced
  #   size: 200b  # Estimated
  #   
  # - source: anthropic
  #   name: claude-3-5-haiku-20241022
  #   expertise:
  #     - fast
  #     - efficient
  #     - compact
  #   size: 20b  # Estimated
  #   
  # # Legacy models
  # - source: anthropic
  #   name: claude-3-opus-20240229
  #   expertise:
  #     - general
  #     - reasoning
  #     - analysis
  #   size: 2000b  # Estimated
  #   
  # - source: anthropic
  #   name: claude-3-haiku-20240307
  #   expertise:
  #     - fast
  #     - efficient
  #   size: 20b  # Estimated

  # Google models (require GOOGLE_API_KEY)
  # Gemini 2.5 Series
  - source: google
    name: gemini-2.5-pro
    expertise:
      - general
      - reasoning
      - code
      - math
      - stem
      - long-context
    size: 1500b  # Estimated
    
  - source: google
    name: gemini-2.5-flash
    expertise:
      - general
      - fast
      - efficient
      - thinking
    size: 80b  # Estimated
    
  - source: google
    name: gemini-2.5-flash-lite-preview-06-17
    expertise:
      - fast
      - efficient
      - compact
      - classification
    size: 8b  # Estimated
    
  # Gemini 2.0 Series
  - source: google
    name: gemini-2.0-flash
    expertise:
      - general
      - fast
      - multimodal
      - native-tools
    size: 70b  # Estimated
    
  - source: google
    name: gemini-2.0-flash-lite
    expertise:
      - fast
      - efficient
      - compact
    size: 8b  # Estimated

defaults:
  expertise_preferences:
    code: qwen2.5-coder:32b
    reasoning: deepseek-r1:32b
    fast: llama3.2:1b
    general: llama3.1:8b
    analysis: gemma3:27b
    compact: gemma3:1b
    vision: meta-llama/Llama-3.2-11B-Vision-Instruct
    
  fallback_chain:
    - llama3.1:8b
    - gemma3:27b
    - mistral:7b
    - llama3.2:3b
    - llama3.2:1b