# Model configuration for the Orchestrator Framework

models:
  # OpenAI Models
  o3:
    provider: openai
    type: openai
    config:
      model_name: o3
      api_key: "${OPENAI_API_KEY}"
      max_retries: 3
      timeout: 30.0
    
  gpt-4.1:
    provider: openai
    type: openai
    config:
      model_name: gpt-4.1
      api_key: "${OPENAI_API_KEY}"
      max_retries: 3
      timeout: 30.0
  
  gpt-o3-mini:
    provider: openai
    type: openai
    config:
      model_name: gpt-o3-mini
      api_key: "${OPENAI_API_KEY}"
      max_retries: 3
      timeout: 30.0
  

  # Anthropic Models
  claude-4-opus:
    provider: anthropic
    type: anthropic
    config:
      model_name: claude-opus-4-20250514
      api_key: "${ANTHROPIC_API_KEY}"
      max_retries: 3
      timeout: 30.0
  
  claude-4-sonnet:
    provider: anthropic
    type: anthropic
    config:
      model_name: claude-sonnet-4-20250514
      api_key: "${ANTHROPIC_API_KEY}"
      max_retries: 3
      timeout: 30.0

  claude-3-7-sonnet:
    provider: anthropic
    type: anthropic
    config:
      model_name: claude-3-7-sonnet-20250219
      api_key: "${ANTHROPIC_API_KEY}"
      max_retries: 3
      timeout: 30.0
  
  # Google Models
  gemini-2.5-pro:
    provider: google
    type: google
    config:
      model_name: gemini-2.5-pro
      api_key: "${GOOGLE_AI_API_KEY}"
      max_retries: 3
      timeout: 30.0
      
  gemini-2.5-flash:
    provider: google
    type: google
    config:
      model_name: gemini-2.5-flash
      api_key: "${GOOGLE_AI_API_KEY}"
      max_retries: 3
      timeout: 30.0

  # HuggingFace Models
  distilgpt2:
    provider: huggingface
    type: huggingface
    config:
      model_name: distilgpt2
      device: auto
      quantization: null
      cache_dir: "${HF_CACHE_DIR}"

  gpt2:
    provider: huggingface
    type: huggingface
    config:
      model_name: gpt2
      device: auto
      quantization: 8bit
      cache_dir: "${HF_CACHE_DIR}"

# Model selection preferences
preferences:
  # Default model for different task types
  default_models:
    generate: gpt-3.5-turbo
    analyze: claude-3-haiku
    transform: gemini-1.5-flash
    code: gpt-4
    reasoning: claude-3-5-sonnet
    vision: gpt-4-turbo
    
  # Fallback order if primary models are unavailable
  fallback_order:
    - gpt-3.5-turbo
    - claude-3-haiku
    - gemini-1.5-flash
    - distilgpt2
    
  # Cost-optimized options
  cost_optimized:
    - gemini-1.5-flash
    - claude-3-haiku
    - gpt-3.5-turbo
    - distilgpt2
    
  # Performance-optimized options
  performance_optimized:
    - gpt-4-turbo
    - claude-3-5-sonnet
    - gemini-1.5-pro
    - gpt-4