# Model configuration for the Orchestrator Framework

models:
  # OpenAI Models
  gpt-4:
    provider: openai
    type: openai
    config:
      model_name: gpt-4
      api_key: "${OPENAI_API_KEY}"
      max_retries: 3
      timeout: 30.0
    
  gpt-4-turbo:
    provider: openai
    type: openai
    config:
      model_name: gpt-4-turbo
      api_key: "${OPENAI_API_KEY}"
      max_retries: 3
      timeout: 30.0
      
  gpt-3.5-turbo:
    provider: openai
    type: openai
    config:
      model_name: gpt-3.5-turbo
      api_key: "${OPENAI_API_KEY}"
      max_retries: 3
      timeout: 30.0

  # Anthropic Models
  claude-3-5-sonnet:
    provider: anthropic
    type: anthropic
    config:
      model_name: claude-3-5-sonnet-20241022
      api_key: "${ANTHROPIC_API_KEY}"
      max_retries: 3
      timeout: 30.0
      
  claude-3-opus:
    provider: anthropic
    type: anthropic
    config:
      model_name: claude-3-opus-20240229
      api_key: "${ANTHROPIC_API_KEY}"
      max_retries: 3
      timeout: 30.0
      
  claude-3-haiku:
    provider: anthropic
    type: anthropic
    config:
      model_name: claude-3-haiku-20240307
      api_key: "${ANTHROPIC_API_KEY}"
      max_retries: 3
      timeout: 30.0

  # Google Models
  gemini-1.5-pro:
    provider: google
    type: google
    config:
      model_name: gemini-1.5-pro
      api_key: "${GOOGLE_AI_API_KEY}"
      max_retries: 3
      timeout: 30.0
      
  gemini-1.5-flash:
    provider: google
    type: google
    config:
      model_name: gemini-1.5-flash
      api_key: "${GOOGLE_AI_API_KEY}"
      max_retries: 3
      timeout: 30.0

  # HuggingFace Models
  distilgpt2:
    provider: huggingface
    type: huggingface
    config:
      model_name: distilgpt2
      device: auto
      quantization: null
      cache_dir: "${HF_CACHE_DIR}"

  gpt2:
    provider: huggingface
    type: huggingface
    config:
      model_name: gpt2
      device: auto
      quantization: 8bit
      cache_dir: "${HF_CACHE_DIR}"

# Model selection preferences
preferences:
  # Default model for different task types
  default_models:
    generate: gpt-3.5-turbo
    analyze: claude-3-haiku
    transform: gemini-1.5-flash
    code: gpt-4
    reasoning: claude-3-5-sonnet
    vision: gpt-4-turbo
    
  # Fallback order if primary models are unavailable
  fallback_order:
    - gpt-3.5-turbo
    - claude-3-haiku
    - gemini-1.5-flash
    - distilgpt2
    
  # Cost-optimized options
  cost_optimized:
    - gemini-1.5-flash
    - claude-3-haiku
    - gpt-3.5-turbo
    - distilgpt2
    
  # Performance-optimized options
  performance_optimized:
    - gpt-4-turbo
    - claude-3-5-sonnet
    - gemini-1.5-pro
    - gpt-4