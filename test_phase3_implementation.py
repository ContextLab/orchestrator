#!/usr/bin/env python3
"""Test Phase 3 implementation: Conditional execution, loops, and error handling."""

import asyncio
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from orchestrator.engine import DeclarativePipelineEngine
from orchestrator.engine.advanced_executor import ConditionalExecutor, LoopExecutor, ErrorRecoveryExecutor
from orchestrator.engine.pipeline_spec import TaskSpec, ErrorHandling, LoopSpec


async def test_conditional_execution():
    """Test conditional execution logic."""
    print("üîÄ Testing Conditional Execution")
    print("-" * 40)
    
    conditional_executor = ConditionalExecutor()
    
    # Test different condition types
    test_cases = [
        {
            "condition": "{{status}} == 'success'",
            "context": {"status": "success"},
            "expected": True
        },
        {
            "condition": "{{count}} > 5",
            "context": {"count": 10},
            "expected": True
        },
        {
            "condition": "{{enabled}} == false",
            "context": {"enabled": False},
            "expected": True
        },
        {
            "condition": "{{results.length}} >= 3",
            "context": {"results": {"length": 5}},
            "expected": True
        },
        {
            "condition": "{{status}} == 'failed'",
            "context": {"status": "success"},
            "expected": False
        }
    ]
    
    for i, case in enumerate(test_cases):
        condition = case["condition"]
        context = case["context"]
        expected = case["expected"]
        
        print(f"\nüß™ Test {i+1}: {condition}")
        print(f"  Context: {context}")
        
        result = conditional_executor.evaluate_condition(condition, context)
        print(f"  Result: {result}")
        
        if result == expected:
            print("  ‚úÖ PASSED")
        else:
            print(f"  ‚ùå FAILED (expected {expected})")
    
    return True


async def test_loop_execution():
    """Test loop execution with different configurations."""
    print("\nüîÑ Testing Loop Execution")
    print("-" * 40)
    
    # Create a mock task executor
    class MockTaskExecutor:
        async def execute_task(self, task_spec, context):
            return {
                "task_id": task_spec.id,
                "success": True,
                "result": f"Processed item: {context.get('loop_item', 'unknown')}",
                "loop_index": context.get("loop_index", 0)
            }
    
    loop_executor = LoopExecutor(MockTaskExecutor())
    
    # Test sequential loop
    task_spec = TaskSpec(
        id="test_loop",
        action="<AUTO>process each item</AUTO>",
        loop=LoopSpec(
            foreach="{{items}}",
            collect_results=True,
            parallel=False
        )
    )
    
    context = {"items": ["apple", "banana", "cherry"]}
    
    print("üîÑ Sequential Loop:")
    result = await loop_executor.execute_loop(task_spec, context)
    print(f"  Iterations: {result['iteration_count']}")
    print(f"  Results: {len(result['loop_results'])}")
    print(f"  Completed: {result['loop_completed']}")
    
    # Test parallel loop
    task_spec.loop.parallel = True
    print("\n‚ö° Parallel Loop:")
    result = await loop_executor.execute_loop(task_spec, context)
    print(f"  Iterations: {result['iteration_count']}")
    print(f"  Mode: {result.get('execution_mode', 'sequential')}")
    
    return True


async def test_error_handling():
    """Test error handling and recovery mechanisms."""
    print("\nüõ°Ô∏è Testing Error Handling")
    print("-" * 40)
    
    # Create a mock task executor that can fail
    class FailingTaskExecutor:
        def __init__(self, fail_count=2):
            self.attempt_count = 0
            self.fail_count = fail_count
        
        async def execute_task(self, task_spec, context):
            self.attempt_count += 1
            
            if self.attempt_count <= self.fail_count:
                raise Exception(f"Simulated failure #{self.attempt_count}")
            
            return {
                "task_id": task_spec.id,
                "success": True,
                "result": f"Success after {self.attempt_count} attempts"
            }
    
    # Test retry logic
    failing_executor = FailingTaskExecutor(fail_count=2)
    error_recovery = ErrorRecoveryExecutor(failing_executor)
    
    task_spec = TaskSpec(
        id="failing_task",
        action="<AUTO>do something that might fail</AUTO>",
        on_error=ErrorHandling(
            action="<AUTO>handle the error gracefully</AUTO>",
            retry_count=3,
            retry_delay=0.1,
            continue_on_error=True
        )
    )
    
    print("üîÑ Testing Retry Logic:")
    print(f"  Task will fail {failing_executor.fail_count} times")
    print(f"  Retry count: {task_spec.on_error.retry_count}")
    
    result = await error_recovery.execute_with_error_handling(task_spec, {})
    
    if result.get("success"):
        print("  ‚úÖ Task succeeded after retries")
        print(f"  Result: {result.get('result', 'No result')}")
    else:
        print("  ‚ö†Ô∏è Task failed after all retries")
        print(f"  Error handled: {result.get('error_handled', False)}")
    
    return True


async def test_advanced_pipeline_features():
    """Test advanced pipeline with conditions, loops, and error handling."""
    print("\nüöÄ Testing Advanced Pipeline Features")
    print("-" * 40)
    
    # Complex pipeline with all advanced features
    advanced_pipeline_yaml = """
name: "Advanced Feature Pipeline"
description: "Test conditional execution, loops, and error handling"
version: "1.0.0"

inputs:
  items:
    type: array
    description: "Items to process"
  enable_validation:
    type: boolean
    description: "Whether to enable validation"
    default: true

steps:
  - id: validate_input
    action: <AUTO>validate the input items {{items}}</AUTO>
    condition: "{{enable_validation}} == true"
    on_error:
      action: <AUTO>provide default validation result</AUTO>
      continue_on_error: true
      retry_count: 2
    
  - id: process_items
    action: <AUTO>process each item in the list</AUTO>
    depends_on: [validate_input]
    loop:
      foreach: "{{items}}"
      parallel: false
      collect_results: true
      max_iterations: 10
    
  - id: summarize_results
    action: <AUTO>create summary of all processed items</AUTO>
    depends_on: [process_items]
    condition: "{{process_items.iteration_count}} > 0"
    cache_results: true
    timeout: 30.0

outputs:
  summary: "{{summarize_results.result}}"
  processed_count: "{{process_items.iteration_count}}"
"""
    
    engine = DeclarativePipelineEngine()
    
    # Validate the advanced pipeline
    validation = await engine.validate_pipeline(advanced_pipeline_yaml)
    print(f"üìã Pipeline Validation: {validation['valid']}")
    
    if validation.get('warnings'):
        for warning in validation['warnings']:
            print(f"  ‚ö†Ô∏è  {warning}")
    
    # Check for advanced features
    print(f"  Steps with conditions: {len([s for s in validation.get('execution_order', []) if hasattr(s, 'condition') and s.condition])}")
    print(f"  Steps with loops: {len([s for s in validation.get('execution_order', []) if hasattr(s, 'loop') and s.loop])}")
    print(f"  Steps with error handling: {len([s for s in validation.get('execution_order', []) if hasattr(s, 'on_error') and s.on_error])}")
    
    print("‚ÑπÔ∏è  Advanced pipeline validation successful - execution requires model integration")
    
    return validation['valid']


async def test_task_spec_enhancements():
    """Test enhanced TaskSpec with new features."""
    print("\nüìã Testing Enhanced TaskSpec")
    print("-" * 40)
    
    # Test task with all advanced features
    task_spec = TaskSpec(
        id="advanced_task",
        action="<AUTO>process data with advanced features</AUTO>",
        condition="{{status}} == 'ready'",
        loop=LoopSpec(
            foreach="{{items}}",
            parallel=True,
            max_iterations=5,
            break_condition="{{item.stop}} == true"
        ),
        on_error=ErrorHandling(
            action="<AUTO>handle error and continue</AUTO>",
            retry_count=3,
            continue_on_error=True,
            fallback_value="default_result"
        ),
        timeout=60.0,
        cache_results=True,
        tags=["advanced", "test"]
    )
    
    print("üîç TaskSpec Feature Detection:")
    print(f"  Has condition: {task_spec.has_condition()}")
    print(f"  Has loop: {task_spec.has_loop()}")
    print(f"  Has error handling: {task_spec.has_error_handling()}")
    print(f"  Is iterative: {task_spec.is_iterative()}")
    print(f"  Is conditional: {task_spec.is_conditional()}")
    print(f"  Should retry on error: {task_spec.should_retry_on_error()}")
    print(f"  Should continue on error: {task_spec.should_continue_on_error()}")
    
    # Test metadata extraction
    metadata = task_spec.get_execution_metadata()
    print(f"\nüìä Execution Metadata:")
    for key, value in metadata.items():
        print(f"  {key}: {value}")
    
    return True


async def test_edge_cases():
    """Test edge cases and error conditions."""
    print("\nüß™ Testing Edge Cases")
    print("-" * 40)
    
    # Test invalid conditions
    conditional_executor = ConditionalExecutor()
    
    edge_cases = [
        ("", {}),  # Empty condition
        ("invalid_syntax", {}),  # Invalid syntax
        ("{{nonexistent}} == true", {}),  # Missing variable
        ("{{deeply.nested.missing}} > 0", {}),  # Missing nested variable
    ]
    
    for condition, context in edge_cases:
        print(f"\nüéØ Edge Case: '{condition}'")
        try:
            result = conditional_executor.evaluate_condition(condition, context)
            print(f"  Result: {result}")
        except Exception as e:
            print(f"  Error: {e}")
    
    # Test empty loop
    loop_executor = LoopExecutor(None)
    
    print("\nüîÑ Empty Loop Test:")
    try:
        empty_items = loop_executor._resolve_loop_items("{{empty_list}}", {"empty_list": []})
        print(f"  Empty loop items: {empty_items}")
    except Exception as e:
        print(f"  Error: {e}")
    
    return True


async def main():
    """Run all Phase 3 tests."""
    print("üß™ Testing Phase 3 Implementation")
    print("=" * 60)
    print("Conditional Execution, Loops, and Error Handling")
    print("=" * 60)
    
    tests = [
        ("Conditional Execution", test_conditional_execution),
        ("Loop Execution", test_loop_execution),
        ("Error Handling", test_error_handling),
        ("Advanced Pipeline Features", test_advanced_pipeline_features),
        ("TaskSpec Enhancements", test_task_spec_enhancements),
        ("Edge Cases", test_edge_cases),
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"\nüìã Test: {test_name}")
        print("=" * 50)
        
        try:
            success = await test_func()
            results.append((test_name, success))
            print(f"\n‚úÖ {test_name} COMPLETED")
        except Exception as e:
            print(f"\n‚ùå {test_name} FAILED: {e}")
            results.append((test_name, False))
    
    print("\n" + "=" * 60)
    print("üìä PHASE 3 TEST SUMMARY")
    print("=" * 60)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"{status} {test_name}")
    
    print(f"\nOverall: {passed}/{total} tests passed")
    
    if passed == total:
        print("üéâ Phase 3 implementation successful!")
        print("üèÜ Declarative Pipeline Engine fully implemented!")
        print("\nüöÄ **FRAMEWORK TRANSFORMATION COMPLETE**")
        print("   ‚úÖ Phase 1: Core engine and AUTO tag resolution")
        print("   ‚úÖ Phase 2: Smart tool discovery and execution")
        print("   ‚úÖ Phase 3: Conditional execution, loops, error handling")
    else:
        print("‚ö†Ô∏è  Some tests failed. Phase 3 needs review.")
    
    return passed == total


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)