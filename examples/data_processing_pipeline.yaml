id: data-processing-pipeline
# Data Processing Pipeline
# Demonstrates data transformation, validation, and analysis

name: data-processing-pipeline
description: Comprehensive data processing workflow
version: "1.0.0"

inputs:
  input_file: "sales_data.csv"
  output_path: "examples/outputs/data_processing_pipeline"
  quality_threshold: 0.95
  enable_profiling: true

steps:
  # Step 1: Read input data
  - id: read_data
    tool: filesystem
    action: read
    parameters:
      path: "{{ output_path }}/{{ input_file }}"
      
  # Step 2: Profile data quality
  - id: profile_data
    tool: data-processing
    action: profile
    condition: "{{ enable_profiling }}"
    parameters:
      data: "{{ read_data.content }}"
      format: "csv"
      profiling_options:
        - missing_values
        - data_types
        - statistical_summary
        - outlier_detection
        - duplicate_detection
    dependencies:
      - read_data
        
  # Step 3: Validate data schema
  - id: validate_schema
    tool: validation
    action: validate
    parameters:
      data: "{{ read_data.content }}"
      schema:
        type: object
        properties:
          order_id:
            type: string
            pattern: "^ORD-[0-9]{6}$"
          customer_id:
            type: string
          product_name:
            type: string
          quantity:
            type: integer
            minimum: 1
          unit_price:
            type: number
            minimum: 0
          order_date:
            type: string
            format: date
          status:
            type: string
            enum: ["pending", "processing", "shipped", "delivered", "cancelled"]
        required: ["order_id", "customer_id", "product_name", "quantity", "unit_price"]
      mode: "LENIENT"  # Try to fix minor issues
    dependencies:
      - read_data
      
  # Step 4: Clean and transform data
  - id: clean_data
    tool: data-processing
    action: transform
    parameters:
      data: "{{ validate_schema.data if validate_schema.valid else read_data.content }}"
      format: "csv"
      output_format: "json"
      operations:
        # Remove duplicates
        - type: deduplicate
          columns: ["order_id"]
          keep: "first"
          
        # Fix data types
        - type: cast
          columns:
            quantity: "integer"
            unit_price: "float"
            order_date: "datetime"
            
        # Handle missing values
        - type: fill_missing
          strategy:
            status: "pending"  # Default status
            quantity: 1        # Default quantity
            
        # Create calculated fields
        - type: calculate
          expressions:
            total_amount: "quantity * unit_price"
            order_month: "DATE_FORMAT(order_date, '%Y-%m')"
            
        # Filter out cancelled orders for analysis
        - type: filter
          condition: "status != 'cancelled'"
    dependencies:
      - validate_schema
          
  # Step 5: Aggregate data for analysis
  - id: aggregate_monthly
    tool: data-processing
    action: aggregate
    parameters:
      data: "{{ clean_data.result }}"
      format: "json"
      output_format: "json"
      group_by: ["order_month", "product_name"]
      aggregations:
        total_quantity:
          column: "quantity"
          function: "sum"
        total_revenue:
          column: "total_amount"
          function: "sum"
        average_price:
          column: "unit_price"
          function: "mean"
        order_count:
          column: "order_id"
          function: "count"
        unique_customers:
          column: "customer_id"
          function: "count_distinct"
    dependencies:
      - clean_data
          
  # Step 6: Statistical analysis
  - id: analyze_trends
    action: analyze_text
    parameters:
      text: "{{ aggregate_monthly.result }}"
      analysis_type: "statistical_trends"
      prompt: |
        Analyze these monthly sales aggregations and provide:
        1. Overall growth rate (as percentage)
        2. Top 5 products by revenue
        3. Any seasonal patterns observed
        4. Any anomalies or unusual trends
        
        Format your response as JSON with these fields:
        - growth_rate: number
        - top_products: array of {product: string, revenue: number}
        - seasonal_patterns: array of strings describing patterns
        - anomalies: array of {month: string, metric: string, description: string}
      model: "<AUTO>"
    dependencies:
      - aggregate_monthly
                  
  # Step 7: Create pivot table
  - id: pivot_analysis
    tool: data-processing
    action: pivot
    parameters:
      data: "{{ clean_data.result }}"
      format: "json"
      output_format: "json"
      index: ["product_name"]
      columns: ["status"]
      values: ["quantity"]
      aggfunc: "sum"
      fill_value: 0
    dependencies:
      - clean_data
      
  # Step 8: Quality check
  - id: quality_check
    action: analyze_text
    parameters:
      text: |
        Original data profile: {{ profile_data.result }}
        Validation results: {{ validate_schema }}
        Rows processed: {{ clean_data.row_count }}
      analysis_type: "quality_assessment"
      prompt: |
        Based on the data profile and validation results, assess the overall data quality.
        Provide a quality score between 0 and 1, where:
        - 1.0 = Perfect quality (no issues)
        - 0.8-0.99 = High quality (minor issues)
        - 0.6-0.79 = Acceptable quality (some issues but usable)
        - Below 0.6 = Poor quality (significant issues)
        
        Also list any data quality issues found and recommendations.
        
        Return as JSON with fields:
        - quality_score: number between 0 and 1
        - issues_found: array of strings
        - recommendations: array of strings
      model: "<AUTO>"
    dependencies:
      - profile_data
      - validate_schema
      - clean_data
              
  # Step 9: Export processed data
  - id: export_data
    tool: data-processing
    action: convert
    parameters:
      data: "{{ clean_data.result }}"
      format: "csv"
    dependencies:
      - clean_data
      
  - id: save_processed
    tool: filesystem
    action: write
    parameters:
      path: "processed_data.csv"
      content: "{{ export_data.result }}"
    dependencies:
      - export_data
      
  # Step 10: Generate data report
  - id: generate_report
    tool: filesystem
    action: write
    parameters:
      path: "data_processing_report.html"
      content: |
        <!DOCTYPE html>
        <html>
        <head>
            <title>Data Processing Report</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                table { border-collapse: collapse; width: 100%; }
                th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
                th { background-color: #4CAF50; color: white; }
                .metric { background-color: #f2f2f2; padding: 10px; margin: 10px 0; }
                .warning { color: #ff9800; }
                .error { color: #f44336; }
                .success { color: #4CAF50; }
            </style>
        </head>
        <body>
            <h1>Data Processing Report</h1>
            
            <div class="metric">
                <h2>Processing Summary</h2>
                <p><strong>Input File:</strong> {{ input_file }}</p>
                <p><strong>Output Path:</strong> {{ output_path }}</p>
                <p><strong>Rows Processed:</strong> {{ clean_data.row_count }}</p>
                <p><strong>Quality Score:</strong> 
                    <span class="{% if quality_check.result.quality_score >= quality_threshold %}success{% else %}warning{% endif %}">
                        {{ quality_check.result.quality_score | round(2) }}
                    </span>
                </p>
            </div>
            
            <h2>Data Quality Issues</h2>
            <ul>
            {% for issue in quality_check.result.issues_found %}
                <li class="warning">{{ issue }}</li>
            {% endfor %}
            </ul>
            
            <h2>Monthly Revenue Trends</h2>
            <table>
                <tr>
                    <th>Month</th>
                    <th>Total Revenue</th>
                    <th>Order Count</th>
                    <th>Unique Customers</th>
                </tr>
                {% for row in aggregate_monthly.result %}
                <tr>
                    <td>{{ row.order_month }}</td>
                    <td>${{ row.total_revenue | round(2) }}</td>
                    <td>{{ row.order_count }}</td>
                    <td>{{ row.unique_customers }}</td>
                </tr>
                {% endfor %}
            </table>
            
            <h2>Top Products</h2>
            <ol>
            {% for product in analyze_trends.result.top_products %}
                <li>{{ product.product }} - ${{ product.revenue | round(2) }}</li>
            {% endfor %}
            </ol>
            
            <h2>Order Status Distribution</h2>
            <table>
                <tr>
                    <th>Product</th>
                    {% for status in ['pending', 'processing', 'shipped', 'delivered'] %}
                    <th>{{ status | title }}</th>
                    {% endfor %}
                </tr>
                {% for row in pivot_analysis.result %}
                <tr>
                    <td>{{ row.product_name }}</td>
                    {% for status in ['pending', 'processing', 'shipped', 'delivered'] %}
                    <td>{{ row[status] or 0 }}</td>
                    {% endfor %}
                </tr>
                {% endfor %}
            </table>
            
            <h2>Recommendations</h2>
            <ul>
            {% for rec in quality_check.result.recommendations %}
                <li>{{ rec }}</li>
            {% endfor %}
            </ul>
            
            <hr>
            <p><em>Report generated on {{ current_date }}</em></p>
        </body>
        </html>
    dependencies:
      - clean_data
      - quality_check
      - aggregate_monthly
      - analyze_trends
      - pivot_analysis
        
  # Step 11: Save report to outputs folder
  - id: save_report
    tool: filesystem
    action: write
    parameters:
      path: "{{ output_path }}/data_processing_report.html"
      content: "{{ generate_report }}"
    dependencies:
      - generate_report
      
  # Step 12: Save processed data to outputs folder
  - id: save_processed_output
    tool: filesystem
    action: write
    parameters:
      path: "{{ output_path }}/processed_data.csv"
      content: "{{ export_data.result }}"
    dependencies:
      - export_data

outputs:
  processed_file: "{{ output_path }}/processed_data.csv"
  quality_score: "{{ quality_check.result.quality_score }}"
  rows_processed: "{{ clean_data.row_count }}"
  report_path: "{{ output_path }}/data_processing_report.html"
  growth_rate: "{{ analyze_trends.result.growth_rate }}"