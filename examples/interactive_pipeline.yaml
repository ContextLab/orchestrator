# Interactive Pipeline with User Input and Approval
# Demonstrates human-in-the-loop workflows
id: interactive_pipeline
name: Interactive Data Processing Pipeline
description: Process data with user input, approval gates, and feedback collection
version: "1.0.0"

parameters:
  input_file:
    type: string
    default: "data/input.csv"
  output_dir:
    type: string
    default: "examples/outputs/interactive_pipeline"

steps:
  - id: get_processing_options
    tool: user-prompt
    action: execute
    parameters:
      prompt: "Select data processing method"
      input_type: "choice"
      choices: ["standard", "advanced", "custom"]
      default: "standard"
      context: "cli"
    
  - id: get_output_format
    tool: user-prompt
    action: execute
    parameters:
      prompt: "Select output format"
      input_type: "choice"
      choices: ["csv", "json", "yaml"]
      default: "csv"
      context: "cli"
    dependencies:
      - get_processing_options
    
  - id: read_data
    tool: filesystem
    action: read
    parameters:
      path: "{{ output_dir }}/{{ input_file }}"
    dependencies:
      - get_output_format
    
  - id: process_data
    tool: data-processing
    action: transform
    parameters:
      data: "{{ read_data.content }}"
      format: "csv"
      operation: "{{ get_processing_options.value }}"
    dependencies:
      - read_data
    
  - id: approve_results
    tool: approval-gate
    action: execute
    parameters:
      title: "Review Processed Data"
      content: "{{ process_data.result | truncate(1000) }}"
      format: "text"
      allow_modifications: true
      require_reason: true
      context: "cli"
    dependencies:
      - process_data
    
  - id: save_if_approved
    tool: filesystem
    action: write
    parameters:
      path: "{{ output_dir }}/data/output.{{ get_output_format.value }}"
      content: "{{ approve_results.modified_content | default(process_data.result) }}"
    dependencies:
      - approve_results
    condition: "{{ approve_results.approved }}"
    
  - id: collect_feedback
    tool: feedback-collection
    action: execute
    parameters:
      title: "Pipeline Experience Feedback"
      questions:
        - id: "ease_of_use"
          text: "How easy was the pipeline to use?"
          type: "rating"
          scale: 5
        - id: "processing_quality"
          text: "Rate the quality of data processing"
          type: "rating"
          scale: 5
        - id: "would_use_again"
          text: "Would you use this pipeline again?"
          type: "boolean"
        - id: "suggestions"
          text: "Any suggestions for improvement?"
          type: "text"
      required_questions: ["ease_of_use", "would_use_again"]
      anonymous: false
      save_to_file: "{{ output_dir }}/feedback/pipeline_feedback.json"
      context: "cli"
    dependencies:
      - save_if_approved
    
  - id: generate_summary
    tool: filesystem
    action: write
    parameters:
      path: "{{ output_dir }}/summary.md"
      content: |
        # Pipeline Execution Summary
        
        ## User Selections
        - Processing Method: {{ get_processing_options.value }}
        - Output Format: {{ get_output_format.value }}
        
        ## Processing Results
        - Input File: {{ input_file }}
        - Processing Status: {{ 'Approved' if approve_results.approved else 'Rejected' }}
        {% if approve_results.approved %}
        - Output File: data/output.{{ get_output_format.value }}
        {% else %}
        - Rejection Reason: {{ approve_results.rejection_reason }}
        {% endif %}
        
        ## Feedback Summary
        - Ease of Use: {{ collect_feedback.summary.rating_average | round(1) }}/5
        - Would Use Again: {{ 'Yes' if collect_feedback.summary.boolean_summary.would_use_again else 'No' }}
        - Completion Rate: {{ collect_feedback.completion_rate }}%
        
        ## Timestamp
        Generated at: {{ now() }}
    dependencies:
      - collect_feedback