# Intelligent Fact-Checker Pipeline
# Demonstrates AUTO tags resolving to lists and runtime for_each expansion

id: intelligent-fact-checker
name: Intelligent Fact-Checker
description: Verifies claims and sources using AUTO tag list generation and runtime parallel processing
version: "3.0.0"

inputs:
  document_source:
    type: string
    description: Path to document file or URL to analyze
    required: true
  strictness:
    type: string
    description: How strict should fact-checking be (lenient/moderate/strict)
    default: "moderate"
  output_path:
    type: string
    description: Path where fact-check report should be saved
    required: false

outputs:
  fact_check_report:
    type: string
    value: "{{ output_path | default('examples/outputs/fact_checker/fact_check_report.md') }}"

steps:
  # Step 1: Load document using filesystem tool
  - id: load_document
    tool: filesystem
    action: read
    parameters:
      path: "{{ document_source }}"
    produces: text
    
  # Step 2: Extract sources as a list using AUTO tag
  - id: extract_sources_list
    dependencies:
      - load_document
    action: generate-structured
    parameters:
      prompt: |
        Analyze this document and extract all sources, citations, and references.
        
        Document content:
        {{ load_document.result }}
        
        Extract each source with its name, URL, and type (journal/report/website/other).
      schema:
        type: object
        properties:
          sources:
            type: array
            items:
              type: object
              properties:
                name:
                  type: string
                url:
                  type: string
                type:
                  type: string
                  enum: ["journal", "report", "website", "other"]
        required: [sources]
      max_completion_tokens: 1000
      model: "claude-sonnet-4-20250514"
    produces: json
    
  # Step 3: Extract claims as a list using AUTO tag
  - id: extract_claims_list
    dependencies:
      - load_document
    action: generate-structured
    parameters:
      prompt: |
        Extract all verifiable factual claims from this document.
        
        Document content:
        {{ load_document.result }}
        
        List each claim as a clear, concise statement that can be fact-checked.
      schema:
        type: object
        properties:
          claims:
            type: array
            items:
              type: string
        required: [claims]
      max_completion_tokens: 1000
      model: "claude-sonnet-4-20250514"
    produces: json
    
  # Step 4: Process sources in parallel using for_each with runtime expansion
  - id: verify_sources
    for_each: "<AUTO>list of sources to verify</AUTO>"
    max_parallel: 2
    add_completion_task: true
    steps:
      - id: verify_source
        action: generate-text
        parameters:
          prompt: |
            Verify this source for authenticity and accuracy:
            Name: {{ item.name }}
            URL: {{ item.url }}
            Type: {{ item.type }}
            
            Check:
            1. Is the source real and accessible?
            2. Is it correctly cited?
            3. Is it a reputable source for its type?
            
            Provide structured analysis:
            - SOURCE: {{ item.name }} ({{ item.url }})
            - STATUS: Valid/Invalid/Questionable
            - CREDIBILITY: High/Medium/Low
            - NOTES: Brief observations
          max_completion_tokens: 300
          model: "claude-sonnet-4-20250514"
    dependencies:
      - extract_sources_list
    
  # Step 5: Process claims in parallel using for_each with runtime expansion
  - id: verify_claims
    for_each: "<AUTO>claims that need fact-checking</AUTO>"
    max_parallel: 3
    add_completion_task: true
    steps:
      - id: verify_claim
        action: generate-text
        parameters:
          prompt: |
            Verify this specific claim: {{ item }}
            Claim number: {{ index }}
            
            Using sources from document for verification.
            
            Provide professional fact-checking analysis:
            - CLAIM {{ index }}: {{ item }}
            - SUPPORT: Yes/Partial/No
            - RELIABILITY: High/Medium/Low
            - EVIDENCE: Brief summary of supporting/contradicting evidence
            - STATUS: Verified/Unverified/Disputed
          max_completion_tokens: 400
          model: "claude-sonnet-4-20250514"
    dependencies:
      - extract_claims_list
    
  # Step 6: Generate final report
  - id: generate_report
    dependencies:
      - verify_sources  # The ForEachTask itself
      - verify_claims   # The ForEachTask itself
      - extract_sources_list
      - extract_claims_list
    action: generate-text
    parameters:
      prompt: |
        Generate a professional fact-checking report for the article "{{ document_source }}".
        
        You have:
        1. Extracted sources: {{ extract_sources_list.result.sources | length }} sources identified
        2. Extracted claims: {{ extract_claims_list.result.claims | length }} claims identified  
        3. Source verifications completed
        4. Claim verifications completed
        
        Create a comprehensive fact-checking report with these sections:
        
        ## Executive Summary
        - Brief overview of the article's topic and main assertions
        - Overall credibility assessment (High/Medium/Low)
        - Number of verified vs unverified claims
        
        ## Source Analysis
        - Credibility of cited sources
        - Any missing or questionable citations
        - Balance between peer-reviewed and industry sources
        
        ## Claim Verification
        For each major claim:
        - Statement of the claim
        - Verification status (Verified/Partially Verified/Unverified/False)
        - Supporting or contradicting evidence
        - Confidence level
        
        ## Red Flags and Concerns
        - Any misleading statements
        - Unsupported assertions
        - Potential biases
        
        ## Conclusion
        - Overall assessment of article accuracy
        - Recommendations for readers
        - Areas requiring further investigation
        
        Focus on providing actionable fact-checking insights about the healthcare AI article's claims and sources.
        Be specific about which claims are well-supported and which require scrutiny.
      max_completion_tokens: 2000
      model: "claude-sonnet-4-20250514"
    produces: text
    
  # Step 7: Save the report
  - id: save_report
    dependencies:
      - generate_report
    tool: filesystem
    action: write
    parameters:
      path: "{{ output_path | default('examples/outputs/fact_checker/fact_check_report.md') }}"
      content: |
        # Fact-Checking Report
        
        **Document:** {{ document_source }}
        **Analysis Date:** {{ execution.timestamp }}
        **Verification Standard:** {{ strictness }}
        
        ---
        
        {{ generate_report.result }}