# Simple Data Processing Pipeline
# Uses real tools: filesystem and data-processing
id: simple_data_processing
name: Simple Data Processing Pipeline
description: Read a CSV file, process it, and save results
version: "1.0.0"

parameters:
  output_path:
    type: string
    default: "examples/outputs/simple_data_processing"
    description: Directory where output files will be saved

steps:
  - id: read_data
    tool: filesystem
    action: read
    parameters:
      path: "data/input.csv"
    
  - id: process_data
    tool: data-processing
    action: filter
    parameters:
      data: "{{ read_data.content }}"
      format: "csv"
      operation:
        criteria:
          status: "active"
    dependencies:
      - read_data
    
  - id: save_results
    tool: filesystem
    action: write
    parameters:
      path: "{{ output_path }}/output_{{ execution.timestamp | slugify }}.csv"
      content: "{{ process_data.processed_data }}"
    dependencies:
      - process_data
      
  - id: save_report
    tool: filesystem
    action: write
    parameters:
      path: "{{ output_path }}/report_{{ execution.timestamp | slugify }}.md"
      content: |
        # Simple Data Processing Report
        
        **Generated:** {{ execution.timestamp }}
        **Pipeline:** Simple Data Processing
        
        ## Processing Summary
        
        - **Input File:** data/input.csv
        - **Filter Applied:** status = "active"
        - **Output File:** {{ output_path }}/output_{{ execution.timestamp | slugify }}.csv
        
        ## Results
        
        The data processing pipeline successfully filtered the input CSV file to include only records with status="active".
        
        ### Filtered Data Preview:
        ```csv
        {{ process_data.processed_data | truncate(500) }}
        ```
        
        ---
        *Generated by Simple Data Processing Pipeline*
    dependencies:
      - process_data