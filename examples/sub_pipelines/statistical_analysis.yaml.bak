# Statistical Analysis Sub-Pipeline
# Performs comprehensive statistical analysis on input data
id: statistical_analysis
name: Statistical Analysis Sub-Pipeline
description: Compute descriptive statistics, correlations, and hypothesis tests
version: "1.0.0"

parameters:
  data:
    type: object
    description: Input data for analysis
  confidence_level:
    type: number
    default: 0.95
    description: Confidence level for statistical tests

steps:
  - id: prepare_data
    tool: python-executor
    parameters:
      code: |
        import pandas as pd
        import numpy as np
        import json
        
        # Convert input data to DataFrame
        data = context.get('data', {})
        if isinstance(data, str):
            try:
                data = json.loads(data)
            except:
                # Try to read as CSV string
                import io
                df = pd.read_csv(io.StringIO(data))
        elif isinstance(data, list):
            df = pd.DataFrame(data)
        elif isinstance(data, dict):
            df = pd.DataFrame([data]) if not any(isinstance(v, (list, dict)) for v in data.values()) else pd.DataFrame(data)
        else:
            df = pd.DataFrame(data)
        
        # Store for next steps
        context['dataframe'] = df
        print(f"Data shape: {df.shape}")
        print(f"Columns: {list(df.columns)}")
        
        result = {
            'rows': len(df),
            'columns': len(df.columns),
            'column_names': list(df.columns)
        }
    
  - id: compute_descriptive_stats
    tool: python-executor
    parameters:
      code: |
        import pandas as pd
        import numpy as np
        from scipy import stats
        
        df = context.get('dataframe', pd.DataFrame())
        confidence_level = context.get('confidence_level', 0.95)
        
        # Compute descriptive statistics
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        stats_dict = {}
        for col in numeric_cols:
            series = df[col].dropna()
            if len(series) > 0:
                # Calculate confidence interval
                mean = series.mean()
                std_err = stats.sem(series)
                ci = stats.t.interval(confidence_level, len(series)-1, loc=mean, scale=std_err)
                
                stats_dict[col] = {
                    'count': int(len(series)),
                    'mean': float(mean),
                    'std': float(series.std()),
                    'min': float(series.min()),
                    'q1': float(series.quantile(0.25)),
                    'median': float(series.median()),
                    'q3': float(series.quantile(0.75)),
                    'max': float(series.max()),
                    'variance': float(series.var()),
                    'skewness': float(series.skew()),
                    'kurtosis': float(series.kurtosis()),
                    'confidence_interval': [float(ci[0]), float(ci[1])] if not np.isnan(ci[0]) else [None, None]
                }
        
        result = stats_dict
        context['descriptive_stats'] = stats_dict
    dependencies:
      - prepare_data
    
  - id: compute_correlations
    tool: python-executor
    parameters:
      code: |
        import pandas as pd
        import numpy as np
        from scipy import stats
        
        df = context.get('dataframe', pd.DataFrame())
        
        # Compute correlation matrix
        numeric_df = df.select_dtypes(include=[np.number])
        
        correlations = {}
        if len(numeric_df.columns) > 1:
            # Pearson correlation
            pearson_corr = numeric_df.corr(method='pearson')
            
            # Spearman correlation (rank-based)
            spearman_corr = numeric_df.corr(method='spearman')
            
            # Convert to dict format
            correlations = {
                'pearson': pearson_corr.to_dict(),
                'spearman': spearman_corr.to_dict(),
                'significant_correlations': []
            }
            
            # Find significant correlations (excluding diagonal)
            for i, col1 in enumerate(pearson_corr.columns):
                for j, col2 in enumerate(pearson_corr.columns):
                    if i < j:  # Upper triangle only
                        corr_value = pearson_corr.iloc[i, j]
                        if abs(corr_value) > 0.5:  # Threshold for significance
                            correlations['significant_correlations'].append({
                                'var1': col1,
                                'var2': col2,
                                'correlation': float(corr_value),
                                'strength': 'strong' if abs(corr_value) > 0.7 else 'moderate'
                            })
        
        result = correlations
        context['correlations'] = correlations
    dependencies:
      - prepare_data
    
  - id: hypothesis_testing
    tool: python-executor
    parameters:
      code: |
        import pandas as pd
        import numpy as np
        from scipy import stats
        
        df = context.get('dataframe', pd.DataFrame())
        confidence_level = context.get('confidence_level', 0.95)
        
        test_results = {}
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        # Normality tests for each numeric column
        for col in numeric_cols[:5]:  # Limit to first 5 columns for performance
            series = df[col].dropna()
            if len(series) > 3:
                # Shapiro-Wilk test for normality
                stat, p_value = stats.shapiro(series[:min(5000, len(series))])  # Limit sample size
                test_results[f'{col}_normality'] = {
                    'test': 'Shapiro-Wilk',
                    'statistic': float(stat),
                    'p_value': float(p_value),
                    'is_normal': p_value > (1 - confidence_level),
                    'interpretation': 'Normally distributed' if p_value > (1 - confidence_level) else 'Not normally distributed'
                }
        
        # If we have at least 2 numeric columns, do t-test
        if len(numeric_cols) >= 2:
            col1, col2 = numeric_cols[0], numeric_cols[1]
            series1 = df[col1].dropna()
            series2 = df[col2].dropna()
            
            if len(series1) > 1 and len(series2) > 1:
                # Independent samples t-test
                stat, p_value = stats.ttest_ind(series1, series2)
                test_results['ttest_independent'] = {
                    'test': f't-test: {col1} vs {col2}',
                    'statistic': float(stat),
                    'p_value': float(p_value),
                    'significant': p_value < (1 - confidence_level),
                    'interpretation': f"Significant difference between {col1} and {col2}" if p_value < (1 - confidence_level) else f"No significant difference between {col1} and {col2}"
                }
        
        # ANOVA if we have categorical and numeric data
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        if categorical_cols and numeric_cols:
            cat_col = categorical_cols[0]
            num_col = numeric_cols[0]
            
            groups = []
            for category in df[cat_col].unique()[:10]:  # Limit to 10 categories
                group_data = df[df[cat_col] == category][num_col].dropna()
                if len(group_data) > 0:
                    groups.append(group_data)
            
            if len(groups) >= 2:
                stat, p_value = stats.f_oneway(*groups)
                test_results['anova'] = {
                    'test': f'ANOVA: {num_col} by {cat_col}',
                    'statistic': float(stat),
                    'p_value': float(p_value),
                    'significant': p_value < (1 - confidence_level),
                    'interpretation': f"Significant differences across {cat_col} groups" if p_value < (1 - confidence_level) else f"No significant differences across {cat_col} groups"
                }
        
        result = test_results
        context['hypothesis_tests'] = test_results
    dependencies:
      - prepare_data
    
  - id: generate_summary
    action: generate_text
    parameters:
      prompt: |
        Based on the statistical analysis results below, provide a concise summary of key findings:
        
        Descriptive Statistics:
        {{ compute_descriptive_stats.result | json }}
        
        Correlations:
        {{ compute_correlations.result | json }}
        
        Hypothesis Tests:
        {{ hypothesis_testing.result | json }}
        
        Provide a 3-4 sentence summary highlighting:
        1. Key characteristics of the data (size, central tendencies)
        2. Important relationships or correlations
        3. Results of statistical tests
        
        Be specific and use actual numbers from the analysis.
      model: <AUTO>
    dependencies:
      - compute_descriptive_stats
      - compute_correlations
      - hypothesis_testing

outputs:
  statistics: "{{ compute_descriptive_stats.result }}"
  correlations: "{{ compute_correlations.result }}"
  hypothesis_tests: "{{ hypothesis_testing.result }}"
  summary: "{{ generate_summary.result }}"
  data_shape: "{{ prepare_data.result }}"