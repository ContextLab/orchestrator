#!/usr/bin/env python3
"""
Run ALL pipelines and save outputs with proper names.
"""

import asyncio
import os
from pathlib import Path
from datetime import datetime
import json
import re
import traceback

from orchestrator.compiler.yaml_compiler import YAMLCompiler
from orchestrator.control_systems.model_based_control_system import ModelBasedControlSystem
from orchestrator.models.model_registry import ModelRegistry
from orchestrator.integrations.openai_model import OpenAIModel
from orchestrator.integrations.anthropic_model import AnthropicModel
from orchestrator.integrations.google_model import GoogleModel
from orchestrator.integrations.ollama_model import OllamaModel
from orchestrator.integrations.huggingface_model import HuggingFaceModel


def setup_models():
    """Set up all available models."""
    registry = ModelRegistry()
    
    # OpenAI models
    if os.getenv("OPENAI_API_KEY"):
        try:
            registry.register_model(OpenAIModel(model_name="gpt-4o"))
            registry.register_model(OpenAIModel(model_name="gpt-4o-mini"))
            print("‚úì OpenAI models registered")
        except Exception as e:
            print(f"‚ö†Ô∏è  OpenAI registration error: {e}")
    
    # Anthropic models
    if os.getenv("ANTHROPIC_API_KEY"):
        try:
            registry.register_model(AnthropicModel(model_name="claude-3-5-sonnet-20241022"))
            registry.register_model(AnthropicModel(model_name="claude-3-haiku-20240307"))
            print("‚úì Anthropic models registered")
        except Exception as e:
            print(f"‚ö†Ô∏è  Anthropic registration error: {e}")
    
    # Google models
    if os.getenv("GOOGLE_API_KEY"):
        try:
            registry.register_model(GoogleModel(model_name="gemini-2.0-flash-exp"))
            registry.register_model(GoogleModel(model_name="gemini-1.5-flash"))
            print("‚úì Google models registered")
        except Exception as e:
            print(f"‚ö†Ô∏è  Google registration error: {e}")
    
    # HuggingFace models
    if os.getenv("HUGGINGFACE_API_KEY"):
        try:
            registry.register_model(HuggingFaceModel(model_name="meta-llama/Llama-3.2-3B-Instruct"))
            print("‚úì HuggingFace models registered")
        except Exception as e:
            print(f"‚ö†Ô∏è  HuggingFace registration error: {e}")
    
    # Ollama models (local)
    try:
        registry.register_model(OllamaModel(model_name="llama3.2"))
        print("‚úì Ollama models registered")
    except Exception as e:
        print(f"‚ö†Ô∏è  Ollama registration error: {e}")
    
    return registry


def extract_save_content(results, pipeline_name):
    """Extract content to save from pipeline results."""
    # Check if there's a save_output or save_conversation result
    for task_id, result in results.items():
        if isinstance(result, str) and ('save' in task_id.lower() or 'file' in task_id.lower()):
            # Look for save instructions
            patterns = [
                r'Save the following content to [^:]+:\s*\n+([\s\S]+)',
                r'Save the .*? to [^:]+:\s*\n+([\s\S]+)',
                r'Write .*? to [^:]+:\s*\n+([\s\S]+)',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, result, re.IGNORECASE | re.MULTILINE)
                if match:
                    return match.group(1).strip()
            
            # If result starts with markdown headers, it might be the content itself
            if result.strip().startswith('#'):
                return result.strip()
    
    # Fallback: create a summary of all results
    content = f"# {pipeline_name.replace('_', ' ').title()}\n\n"
    content += f"*Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n\n"
    content += "## Pipeline Results\n\n"
    
    for task_id, result in results.items():
        if task_id != 'save_output' and isinstance(result, str):
            content += f"### {task_id.replace('_', ' ').title()}\n\n"
            content += f"{result[:500]}{'...' if len(result) > 500 else ''}\n\n"
    
    content += "---\n*Generated by Orchestrator Pipeline*"
    return content


async def run_pipeline(name, yaml_path, inputs, registry):
    """Run a single pipeline and save output."""
    print(f"\n{'='*80}")
    print(f"üîÑ Running: {name}")
    print(f"üìÑ File: {yaml_path}")
    print(f"{'='*80}")
    
    try:
        # Read YAML
        with open(yaml_path, 'r') as f:
            yaml_content = f.read()
        
        # Setup
        control_system = ModelBasedControlSystem(registry)
        compiler = YAMLCompiler()
        
        # Compile and run
        print(f"üìä Inputs: {json.dumps(inputs, indent=2)}")
        pipeline = await compiler.compile(yaml_content, inputs)
        print(f"‚úì Compiled with {len(pipeline.tasks)} tasks")
        
        start = datetime.now()
        results = await control_system.execute_pipeline(pipeline)
        duration = (datetime.now() - start).total_seconds()
        
        print(f"‚úÖ Completed in {duration:.1f} seconds")
        
        # Extract and save content
        pipeline_name = yaml_path.stem
        content = extract_save_content(results, pipeline_name)
        
        # Save to file
        output_file = Path(f"examples/output/{pipeline_name}.md")
        output_file.parent.mkdir(parents=True, exist_ok=True)
        output_file.write_text(content)
        
        file_size = output_file.stat().st_size
        print(f"üìù Saved: {output_file} ({file_size:,} bytes)")
        
        return {
            "status": "success",
            "duration": duration,
            "output_file": str(output_file),
            "file_size": file_size
        }
        
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        traceback.print_exc()
        return {
            "status": "error",
            "error": str(e)
        }


async def run_all_pipelines():
    """Run all pipelines with appropriate test inputs."""
    print("üöÄ Running ALL Pipelines")
    print("="*80)
    
    # Set up models
    registry = setup_models()
    
    # Define ALL pipelines with test inputs
    all_pipelines = [
        # Simple working examples
        {
            "name": "Research Simple",
            "file": Path("examples/working/research_simple.yaml"),
            "inputs": {
                "query": "The Impact of Artificial Intelligence on Healthcare",
                "depth": "comprehensive"
            }
        },
        {
            "name": "Content Simple",
            "file": Path("examples/working/content_simple.yaml"),
            "inputs": {
                "topic": "Best Practices for Cloud Native Development",
                "audience": "software engineers",
                "tone": "technical"
            }
        },
        {
            "name": "Creative Simple",
            "file": Path("examples/working/creative_simple.yaml"),
            "inputs": {
                "theme": "A World Where Dreams Are Currency",
                "genre": "science fiction",
                "length": "flash"
            }
        },
        {
            "name": "Analysis Simple",
            "file": Path("examples/working/analysis_simple.yaml"),
            "inputs": {
                "code_path": "src/orchestrator/core",
                "language": "python"
            }
        },
        {
            "name": "Data Simple",
            "file": Path("examples/working/data_simple.yaml"),
            "inputs": {
                "data_source": "Customer Satisfaction Survey Results",
                "process_type": "analyze"
            }
        },
        
        # Main examples
        {
            "name": "Research Assistant",
            "file": Path("examples/research_assistant.yaml"),
            "inputs": {
                "query": "Quantum Computing Applications in Cryptography",
                "context": "Focus on post-quantum cryptography and current threats",
                "max_sources": 10,
                "quality_threshold": 0.8
            }
        },
        {
            "name": "Content Creation Pipeline",
            "file": Path("examples/content_creation_pipeline.yaml"),
            "inputs": {
                "topic": "The Future of Remote Work Technology",
                "formats": ["blog", "social", "email"],
                "audience": "business leaders",
                "brand_voice": "professional and forward-thinking",
                "target_length": 2000,
                "auto_publish": False
            }
        },
        {
            "name": "Creative Writing Assistant",
            "file": Path("examples/creative_writing_assistant.yaml"),
            "inputs": {
                "genre": "science fiction",
                "length": "short",
                "writing_style": "descriptive",
                "target_audience": "young adults",
                "initial_premise": "A society where memories can be traded",
                "include_worldbuilding": True,
                "chapter_count": 3
            }
        },
        {
            "name": "Financial Analysis Bot",
            "file": Path("examples/financial_analysis_bot.yaml"),
            "inputs": {
                "symbols": ["AAPL", "GOOGL", "MSFT"],
                "analysis_type": "technical",
                "time_period": "3M",
                "include_fundamentals": True,
                "backtest_period": "6M"
            }
        },
        {
            "name": "Data Processing Workflow",
            "file": Path("examples/data_processing_workflow.yaml"),
            "inputs": {
                "source": "sales_data_2024.csv",
                "output_path": "processed/sales_insights",
                "output_format": "parquet",
                "chunk_size": 5000,
                "parallel_workers": 4,
                "validation_rules": [
                    {"field": "order_id", "type": "required"},
                    {"field": "amount", "type": "numeric", "min": 0},
                    {"field": "date", "type": "date"}
                ],
                "transformations": [
                    {"type": "normalize_currency", "field": "amount"},
                    {"type": "extract_quarter", "field": "date"},
                    {"type": "categorize_customer", "field": "customer_type"}
                ]
            }
        },
        {
            "name": "Interactive Chat Bot Demo",
            "file": Path("examples/interactive_chat_bot_demo.yaml"),
            "inputs": {
                "conversation_topic": "Understanding Machine Learning Basics",
                "num_exchanges": 5,
                "user_persona": "curious-beginner",
                "bot_persona": "friendly-expert"
            }
        },
        {
            "name": "Code Analysis Suite",
            "file": Path("examples/code_analysis_suite.yaml"),
            "inputs": {
                "repository_path": "./src",
                "analysis_types": ["quality", "security", "complexity"],
                "languages": ["python"],
                "output_format": "markdown",
                "fix_issues": False,
                "severity_threshold": "medium"
            }
        },
        {
            "name": "Customer Support Automation",
            "file": Path("examples/customer_support_automation.yaml"),
            "inputs": {
                "ticket_id": "TICKET-54321",
                "customer_message": "My subscription isn't showing the premium features even though I upgraded yesterday.",
                "customer_history": {
                    "previous_tickets": 1,
                    "account_type": "premium",
                    "customer_since": "2023-06-15"
                },
                "escalation_threshold": 0.7,
                "auto_respond": True
            }
        },
        {
            "name": "Automated Testing System",
            "file": Path("examples/automated_testing_system.yaml"),
            "inputs": {
                "source_dir": "./src/orchestrator",
                "test_dir": "./tests",
                "coverage_target": 85.0,
                "test_types": ["unit", "integration"],
                "test_framework": "pytest",
                "include_edge_cases": True,
                "include_performance": True
            }
        },
        {
            "name": "Document Intelligence",
            "file": Path("examples/document_intelligence.yaml"),
            "inputs": {
                "document_path": "contract_template.pdf",
                "analysis_types": ["summary", "key_terms", "risks", "obligations"],
                "output_format": "structured_json",
                "extract_entities": True,
                "languages": ["en"]
            }
        },
        {
            "name": "Multi Agent Collaboration",
            "file": Path("examples/multi_agent_collaboration.yaml"),
            "inputs": {
                "task": "Design a sustainable urban transportation system",
                "num_agents": 4,
                "agent_roles": ["urban_planner", "environmental_expert", "tech_innovator", "community_advocate"],
                "collaboration_rounds": 3,
                "consensus_threshold": 0.8
            }
        },
        {
            "name": "Scalable Customer Service Agent",
            "file": Path("examples/scalable_customer_service_agent.yaml"),
            "inputs": {
                "customer_id": "CUST-123456",
                "query": "How do I change my delivery address for order #ORD-789?",
                "channel": "chat",
                "language": "en",
                "priority": "high",
                "account_type": "premium"
            }
        },
        {
            "name": "Multi Model Pipeline",
            "file": Path("examples/multi_model_pipeline.yaml"),
            "inputs": {
                "topic": "renewable energy trends",
                "models_to_use": ["openai", "anthropic", "google"]
            }
        },
        {
            "name": "Simple Pipeline",
            "file": Path("examples/simple_pipeline.yaml"),
            "inputs": {
                "message": "Explain the concept of neural networks",
                "style": "simple"
            }
        }
    ]
    
    # Run each pipeline
    results = []
    successful = 0
    failed = 0
    
    for pipeline_config in all_pipelines:
        if pipeline_config["file"].exists():
            result = await run_pipeline(
                pipeline_config["name"],
                pipeline_config["file"],
                pipeline_config["inputs"],
                registry
            )
            
            result["name"] = pipeline_config["name"]
            results.append(result)
            
            if result["status"] == "success":
                successful += 1
            else:
                failed += 1
                
            # Small delay to avoid rate limiting
            await asyncio.sleep(2)
        else:
            print(f"\n‚ö†Ô∏è  Skipping {pipeline_config['name']} - file not found: {pipeline_config['file']}")
            failed += 1
    
    # Summary
    print("\n" + "="*80)
    print("FINAL SUMMARY")
    print("="*80)
    
    print(f"\nüìä Total pipelines: {len(all_pipelines)}")
    print(f"‚úÖ Successful: {successful}")
    print(f"‚ùå Failed: {failed}")
    
    print("\nüìã Detailed Results:")
    for result in results:
        if result["status"] == "success":
            print(f"‚úÖ {result['name']:<35} - {result['output_file']} ({result['file_size']:,} bytes)")
        else:
            print(f"‚ùå {result['name']:<35} - {result['error'][:50]}...")
    
    # List all output files
    print("\nüìÅ All Output Files:")
    output_files = sorted(Path("examples/output").glob("*.md"))
    
    for f in output_files[-20:]:  # Show last 20 files
        size = f.stat().st_size
        mod_time = datetime.fromtimestamp(f.stat().st_mtime).strftime("%Y-%m-%d %H:%M")
        print(f"  {f.name:<50} ({size:>8,} bytes) [{mod_time}]")
    
    print(f"\n‚ú® Pipeline execution complete!")
    print(f"üìÇ All outputs saved in examples/output/")
    
    return results


async def main():
    """Main entry point."""
    # Ensure output directory exists
    Path("examples/output").mkdir(parents=True, exist_ok=True)
    
    # Run all pipelines
    results = await run_all_pipelines()
    
    # Save execution summary
    summary = {
        "execution_date": datetime.now().isoformat(),
        "total_pipelines": len(results),
        "successful": sum(1 for r in results if r["status"] == "success"),
        "failed": sum(1 for r in results if r["status"] == "error"),
        "results": results
    }
    
    summary_file = Path("examples/output/execution_summary.json")
    with open(summary_file, 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nüìä Execution summary saved to: {summary_file}")


if __name__ == "__main__":
    # Check API keys
    print("üîë API Key Status:")
    apis = {
        "OPENAI_API_KEY": "OpenAI",
        "ANTHROPIC_API_KEY": "Anthropic", 
        "GOOGLE_API_KEY": "Google",
        "HUGGINGFACE_API_KEY": "HuggingFace"
    }
    
    for key, name in apis.items():
        status = "‚úÖ" if os.getenv(key) else "‚ùå"
        print(f"  {name}: {status}")
    
    print("\nStarting pipeline execution...\n")
    asyncio.run(main())