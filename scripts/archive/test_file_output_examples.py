#!/usr/bin/env python3
"""
Test examples with file output capability.
Shows how pipelines save their results to markdown files.
"""

import asyncio
import os
from pathlib import Path

from orchestrator.compiler.yaml_compiler import YAMLCompiler
from orchestrator.control_systems.model_based_control_system import ModelBasedControlSystem
from orchestrator.models.model_registry import ModelRegistry
from orchestrator.integrations.openai_model import OpenAIModel
from orchestrator.integrations.anthropic_model import AnthropicModel
from orchestrator.integrations.google_model import GoogleModel
from orchestrator.integrations.ollama_model import OllamaModel
from orchestrator.integrations.huggingface_model import HuggingFaceModel


async def test_research_with_output():
    """Test research assistant with file output."""
    print("=" * 60)
    print("Testing Research Assistant with Google Gemini")
    print("=" * 60)
    
    # Setup
    model_registry = ModelRegistry()
    model = GoogleModel(model_name="gemini-1.5-flash")
    model_registry.register_model(model)
    
    control_system = ModelBasedControlSystem(model_registry)
    compiler = YAMLCompiler()
    
    # Create simple test YAML with file output
    yaml_content = '''
name: "Quick Research Test"
description: "Test research with file output"
model: "google/gemini-1.5-flash"

inputs:
  query:
    type: string
    required: true

steps:
  - id: research
    action: |
      Research the topic: {{query}}
      
      Provide:
      1. Key concepts and definitions
      2. Current trends and developments
      3. Practical applications
      4. Future outlook
      
  - id: save_output
    action: |
      Write the following content to examples/output/research_{{query | replace(' ', '_') | lower}}.md:
      
      # Research Report: {{query}}
      
      *Generated on: {{execution.timestamp}}*
      *Model: Google Gemini 1.5 Flash*
      
      ## Research Results
      
      {{research.result}}
      
      ---
      *Generated by Orchestrator Research Pipeline*
    depends_on: [research]

outputs:
  report: "{{research.result}}"
  file_path: "examples/output/research_{{query | replace(' ', '_') | lower}}.md"
'''
    
    # Test
    inputs = {"query": "quantum computing basics"}
    
    try:
        pipeline = await compiler.compile(yaml_content, inputs)
        results = await control_system.execute_pipeline(pipeline)
        
        print(f"Research completed!")
        print(f"File should be saved at: {results.get('save_output', {}).get('file_path', 'Unknown')}")
        
        return True
    except Exception as e:
        print(f"Error: {e}")
        return False


async def test_chatbot_demo():
    """Test chatbot demo with simulated conversation."""
    print("\n" + "=" * 60)
    print("Testing Interactive Chatbot Demo")
    print("=" * 60)
    
    # Setup with multiple models
    model_registry = ModelRegistry()
    
    # User simulator (OpenAI)
    user_model = OpenAIModel(model_name="gpt-4o-mini")
    model_registry.register_model(user_model)
    
    # Bot (Anthropic)
    bot_model = AnthropicModel(model_name="claude-3-haiku-20240307")
    model_registry.register_model(bot_model)
    
    control_system = ModelBasedControlSystem(model_registry)
    
    # Simple demo
    yaml_content = '''
name: "Chatbot Demo"
description: "Simple chatbot conversation demo"

inputs:
  topic:
    type: string
    default: "machine learning"

steps:
  - id: user_msg
    action: |
      As a curious student, ask an interesting question about {{topic}}.
      Be natural and conversational.
    model: "openai/gpt-4o-mini"
    
  - id: bot_response
    action: |
      As a helpful teacher, respond to: {{user_msg.result}}
      
      Provide a clear, informative answer with examples.
    model: "anthropic/claude-3-haiku-20240307"
    depends_on: [user_msg]
    
  - id: save_conversation
    action: |
      Write to examples/output/chat_demo_{{topic | replace(' ', '_')}}.md:
      
      # Chatbot Demo: {{topic}}
      
      ## Conversation
      
      **User (GPT-4):** {{user_msg.result}}
      
      **Bot (Claude):** {{bot_response.result}}
      
      ---
      *Demo conversation between AI models*
    depends_on: [bot_response]

outputs:
  conversation_file: "examples/output/chat_demo_{{topic | replace(' ', '_')}}.md"
'''
    
    compiler = YAMLCompiler()
    
    try:
        pipeline = await compiler.compile(yaml_content, {"topic": "neural networks"})
        results = await control_system.execute_pipeline(pipeline)
        
        print("Chatbot demo completed!")
        print(f"Conversation saved to: {results.get('save_conversation', {}).get('file_path', 'Unknown')}")
        
        return True
    except Exception as e:
        print(f"Error: {e}")
        return False


async def test_content_creation():
    """Test content creation with HuggingFace model."""
    print("\n" + "=" * 60)
    print("Testing Content Creation with HuggingFace")
    print("=" * 60)
    
    # Setup
    model_registry = ModelRegistry()
    model = HuggingFaceModel(model_name="mistralai/Mistral-7B-Instruct-v0.2")
    model_registry.register_model(model)
    
    control_system = ModelBasedControlSystem(model_registry)
    compiler = YAMLCompiler()
    
    yaml_content = '''
name: "Content Creation Test"
model: "huggingface/mistralai/Mistral-7B-Instruct-v0.2"

inputs:
  topic:
    type: string
    required: true

steps:
  - id: create_content
    action: |
      Write a short blog post about: {{topic}}
      
      Include:
      1. Engaging introduction
      2. Main points with examples
      3. Practical tips
      4. Conclusion
      
  - id: save_content
    action: |
      Write to examples/output/content_{{topic | replace(' ', '_') | lower}}.md:
      
      # Blog Post: {{topic}}
      
      *Created with HuggingFace Mistral-7B*
      
      {{create_content.result}}
      
      ---
      *Generated by Orchestrator Content Pipeline*
    depends_on: [create_content]

outputs:
  content: "{{create_content.result}}"
  file_path: "examples/output/content_{{topic | replace(' ', '_') | lower}}.md"
'''
    
    try:
        pipeline = await compiler.compile(yaml_content, {"topic": "sustainable technology"})
        results = await control_system.execute_pipeline(pipeline)
        
        print("Content created!")
        print(f"Saved to: {results.get('save_content', {}).get('file_path', 'Unknown')}")
        
        return True
    except Exception as e:
        print(f"Error: {e}")
        return False


async def main():
    """Run all tests."""
    print("Testing File Output Examples")
    print("This demonstrates how pipelines save results to markdown files")
    print("-" * 60)
    
    # Ensure output directory exists
    Path("examples/output").mkdir(parents=True, exist_ok=True)
    
    # Check for API keys
    api_keys = {
        "OPENAI_API_KEY": "OpenAI",
        "ANTHROPIC_API_KEY": "Anthropic", 
        "GOOGLE_API_KEY": "Google",
        "HUGGINGFACE_API_KEY": "HuggingFace"
    }
    
    missing_keys = []
    for key, name in api_keys.items():
        if not os.getenv(key):
            missing_keys.append(name)
    
    if missing_keys:
        print(f"Warning: Missing API keys for: {', '.join(missing_keys)}")
        print("Some tests may fail without proper API keys")
        print()
    
    # Run tests
    tests = [
        ("Research with Google", test_research_with_output),
        ("Chatbot Demo", test_chatbot_demo),
        ("Content Creation with HuggingFace", test_content_creation)
    ]
    
    results = []
    for name, test_func in tests:
        try:
            success = await test_func()
            results.append((name, success))
        except Exception as e:
            print(f"Test {name} crashed: {e}")
            results.append((name, False))
    
    # Summary
    print("\n" + "=" * 60)
    print("Test Summary")
    print("=" * 60)
    
    for name, success in results:
        status = "✅ PASS" if success else "❌ FAIL"
        print(f"{name}: {status}")
    
    print("\nCheck the examples/output/ directory for generated markdown files!")
    print("\nNote: To use Ollama models, ensure Ollama is running locally.")


if __name__ == "__main__":
    asyncio.run(main())