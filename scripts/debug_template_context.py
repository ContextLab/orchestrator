#!/usr/bin/env python3
"""Debug template context in pipeline execution."""

import asyncio
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from orchestrator import Orchestrator, init_models
from orchestrator.control_systems.hybrid_control_system import HybridControlSystem


# Patch the HybridControlSystem to log context
original_build_template_context = HybridControlSystem._build_template_context

def debug_build_template_context(self, context):
    result = original_build_template_context(self, context)
    print(f"\nüîç Debug: Template context for task '{context.get('task_id', 'unknown')}':")
    print(f"  - Has previous_results: {'previous_results' in context}")
    if 'previous_results' in context:
        print(f"  - Previous results keys: {list(context['previous_results'].keys())}")
    print(f"  - Template context keys: {list(result.keys())}")
    if 'generate_content' in result:
        print(f"  - generate_content value: {result['generate_content']}")
    return result

HybridControlSystem._build_template_context = debug_build_template_context


async def test_simple_research():
    """Test simple research pipeline."""
    # Initialize models
    print("Initializing models...")
    init_models()
    
    # Create orchestrator
    orchestrator = Orchestrator()
    
    # Simple test pipeline
    yaml_content = """
id: test-template-fix
name: Test Template Fix
description: Test our template rendering fixes

parameters:
  topic:
    type: string
    default: "AI"
  output_dir:
    type: string
    default: "test_output"

steps:
  - id: generate_content
    action: generate_text
    parameters:
      prompt: "Write a brief summary about {{ topic }}"
      model: openai/gpt-4o-mini
      max_tokens: 100
  
  - id: save_result
    tool: filesystem
    action: write
    parameters:
      path: "{{ output_dir }}/{{ topic | slugify }}_summary.md"
      content: |
        # Summary: {{ topic }}
        
        **Date:** {{ execution.timestamp }}
        **Output Directory:** {{ output_dir }}
        
        ## Content
        
        {{ generate_content.result }}
        
        ---
        *Generated by Test Pipeline*
    dependencies:
      - generate_content

outputs:
  summary: "{{ generate_content.result }}"
  file_path: "{{ save_result.filepath | default('Not saved') }}"
"""
    
    # Run pipeline
    inputs = {"topic": "artificial intelligence", "output_dir": "test_results"}
    
    try:
        results = await orchestrator.execute_yaml(yaml_content, inputs)
        print("\n‚úÖ Pipeline executed successfully!")
        print(f"Outputs: {results.get('outputs', {})}")
        
        # Check if file was created
        output_files = list(Path(".").glob("test_results/*.md"))
        if output_files:
            print(f"\nFiles created: {[str(f) for f in output_files]}")
            # Read and display content
            content = output_files[0].read_text()
            print(f"\nFile content:\n{content}")
        else:
            print("\nNo output files found")
        
    except Exception as e:
        print(f"\n‚ùå Pipeline failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(test_simple_research())