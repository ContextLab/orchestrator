#!/usr/bin/env python3
"""
Test pipeline file output with corrected YAML syntax.
"""

import asyncio
import os
from pathlib import Path
from datetime import datetime
import json

from orchestrator.compiler.yaml_compiler import YAMLCompiler
from orchestrator.control_systems.model_based_control_system import ModelBasedControlSystem
from orchestrator.models.model_registry import ModelRegistry
from orchestrator.integrations.google_model import GoogleModel
from orchestrator.integrations.anthropic_model import AnthropicModel
from orchestrator.integrations.openai_model import OpenAIModel


async def test_corrected_file_output():
    """Test file output with proper action format."""
    print("üß™ Testing Corrected File Output")
    print("="*80)
    
    # Setup models
    registry = ModelRegistry()
    
    if os.getenv("GOOGLE_API_KEY"):
        registry.register_model(GoogleModel(model_name="gemini-1.5-flash"))
    if os.getenv("ANTHROPIC_API_KEY"):
        registry.register_model(AnthropicModel(model_name="claude-3-haiku-20240307"))
    if os.getenv("OPENAI_API_KEY"):
        registry.register_model(OpenAIModel(model_name="gpt-4o-mini"))
    
    # Create test pipeline - the action needs to be a prompt that asks to save file
    yaml_content = '''name: "Test File Output"
description: "Test saving outputs to files"
model: "openai/gpt-4o-mini"

inputs:
  topic:
    type: string
    required: true

steps:
  - id: generate_content
    action: |
      Write a comprehensive article about: {{topic}}
      
      Include:
      1. Introduction (2-3 paragraphs)
      2. Three main points with explanations
      3. Practical examples
      4. Conclusion with key takeaways
      
      Make it approximately 500 words.
    
  - id: save_to_file
    action: |
      Save the following content to the file examples/output/article_{{topic | replace(' ', '_') | lower}}.md:
      
      # {{topic}}
      
      Generated on: {{execution.timestamp}}
      
      {{generate_content.result}}
      
      ---
      Generated by Orchestrator Test Pipeline
    depends_on: [generate_content]

outputs:
  content: "{{generate_content.result}}"
  saved_file: "examples/output/article_{{topic | replace(' ', '_') | lower}}.md"
'''
    
    # Ensure output directory exists
    Path("examples/output").mkdir(parents=True, exist_ok=True)
    
    # Setup
    control_system = ModelBasedControlSystem(registry)
    compiler = YAMLCompiler()
    
    # Test inputs
    test_cases = [
        {"topic": "Benefits of Continuous Integration"},
        {"topic": "Modern Software Architecture Patterns"},
        {"topic": "DevOps Best Practices"}
    ]
    
    for inputs in test_cases:
        print(f"\n{'='*60}")
        print(f"Testing: {inputs['topic']}")
        print(f"{'='*60}")
        
        try:
            # Compile and run
            pipeline = await compiler.compile(yaml_content, inputs)
            print(f"‚úì Pipeline compiled with {len(pipeline.tasks)} tasks")
            
            start = datetime.now()
            results = await control_system.execute_pipeline(pipeline)
            duration = (datetime.now() - start).total_seconds()
            
            print(f"‚úÖ Completed in {duration:.1f} seconds")
            
            # Check results
            for task_id, result in results.items():
                if 'save' in task_id:
                    print(f"\n{task_id} result preview:")
                    print(result[:200] + "..." if len(result) > 200 else result)
            
            # Check expected file
            expected_file = f"examples/output/article_{inputs['topic'].replace(' ', '_').lower()}.md"
            if Path(expected_file).exists():
                print(f"\n‚úÖ File created: {expected_file}")
                print(f"   Size: {Path(expected_file).stat().st_size} bytes")
                
                # Read first few lines
                with open(expected_file, 'r') as f:
                    lines = f.readlines()[:5]
                    print("\n   Preview:")
                    for line in lines:
                        print(f"   {line.rstrip()}")
            
        except Exception as e:
            print(f"\n‚ùå Error: {str(e)}")
    
    # List all generated files
    print(f"\n{'='*60}")
    print("üìÅ All Generated Files:")
    print(f"{'='*60}")
    
    output_files = list(Path("examples/output").glob("article_*.md"))
    for f in sorted(output_files):
        size = f.stat().st_size
        print(f"  - {f.name:<50} ({size:>6,} bytes)")
    
    print(f"\n‚ú® Test complete!")


if __name__ == "__main__":
    asyncio.run(test_corrected_file_output())