---
id: 002
title: Repository Cleanup & Organization (GitHub #2)
epic: validate-all-example-pipelines-with-manual-checks
created: 2025-08-25T18:45:00Z
updated: 2025-08-25T23:45:45Z
github: https://github.com/ContextLab/orchestrator/issues/276
status: completed
priority: high
estimated_hours: 8
depends_on: []
parallel: true
week: 1
github_issues: [2]
---

# Repository Cleanup & Organization (GitHub #2)

Clean up repository structure, remove temporary files, and establish consistent organization for examples, data, and outputs to create a professional, maintainable codebase.

## Problem Statement

The repository has organizational issues that create an unprofessional appearance and confuse users:

1. **Temporary Files Scattered**: .tmp, debug_, temp_ files throughout repository
2. **Inconsistent Data Locations**: Example data files in multiple inconsistent locations
3. **Debug Scripts Misplaced**: Test scripts and backup files in wrong directories
4. **Output Directory Chaos**: Pipeline outputs in inconsistent locations and formats
5. **Documentation Structure**: README files and tutorials in various locations

## Current State Analysis

### Temporary/Debug Files Found:
```bash
# Temporary files to remove
/Users/jmanning/orchestrator/src/orchestrator/core/error_handler.py.tmp
/Users/jmanning/orchestrator/temp/safety_backups/root_org_backup_20250825_104603/
/Users/jmanning/orchestrator/.mypy_cache/
```

### Data File Locations (Need Consolidation):
```bash
# Current scattered locations
examples/data/                    # Some shared data
examples/test_data/              # Test-specific data
examples/config/                 # Configuration files
examples/outputs/*/              # Pipeline outputs (inconsistent structure)
```

### Script Organization Issues:
```bash
# Scripts in wrong locations
temp/safety_backups/.../test_*.yaml
temp/safety_backups/.../test_*.py
scripts/*.py (some test scripts mixed with production)
```

## Target Repository Structure

### Clean Organization Goal:
```
orchestrator/
├── examples/
│   ├── data/                          # All shared input data
│   │   ├── sample_data.csv
│   │   ├── customers.json
│   │   ├── raw_data.csv
│   │   └── ...
│   ├── outputs/                       # Pipeline-specific outputs
│   │   ├── simple_data_processing/
│   │   │   ├── output_<input-specific>.csv
│   │   │   └── report_<input-specific>.md
│   │   ├── research_minimal/
│   │   └── .../<pipeline-name>/
│   ├── test_data/                     # Test-specific data only
│   ├── tutorials/                     # Pipeline tutorials
│   ├── templates/                     # Shared templates
│   ├── config/                        # Shared configuration
│   └── README.md                      # Examples overview
├── scripts/
│   ├── pipeline_testing/              # Pipeline test scripts
│   ├── maintenance/                   # Maintenance scripts
│   └── production/                    # Production deployment scripts
├── tests/
│   ├── unit/
│   ├── integration/
│   └── pipeline_validation/           # Pipeline-specific tests
└── docs/
    ├── tutorials/                     # User tutorials
    ├── development/                   # Developer documentation  
    └── api/                          # API documentation
```

## Implementation Tasks

### Phase 1: Cleanup Operations
- [ ] **Remove Temporary Files**: Delete all .tmp, debug_, temp_ files
- [ ] **Clean Cache Directories**: Remove .mypy_cache, __pycache__ files
- [ ] **Remove Safety Backups**: Clean up temp/safety_backups/ directory
- [ ] **Archive Old Test Files**: Move scattered test files to appropriate locations

### Phase 2: Data File Consolidation
- [ ] **Audit Data Locations**: Inventory all data files across repository
- [ ] **Consolidate Input Data**: Move shared data to `examples/data/`
- [ ] **Organize Test Data**: Move test-specific data to `examples/test_data/`
- [ ] **Clean Output Directories**: Standardize pipeline output locations

### Phase 3: Script Organization
- [ ] **Categorize Scripts**: Sort scripts by purpose (testing, maintenance, production)
- [ ] **Create Directory Structure**: Establish `scripts/` subdirectories
- [ ] **Move Scripts**: Relocate scripts to appropriate directories
- [ ] **Update Import Paths**: Fix any broken imports after moves

### Phase 4: Documentation Structure
- [ ] **README Organization**: Ensure consistent README structure
- [ ] **Tutorial Placement**: Standardize tutorial locations
- [ ] **Cross-Reference Updates**: Fix links after file moves
- [ ] **Documentation Index**: Create master documentation index

## File Movement Plan

### Data File Consolidation:
```bash
# Move shared input data
examples/data/customers.json → examples/data/customers.json ✓ (already correct)
examples/data/sales_data.csv → examples/data/sales_data.csv ✓ (already correct)
examples/data/input.csv → examples/data/input.csv ✓ (already correct)
```

### Output Directory Standardization:
```bash
# Ensure consistent output structure
examples/outputs/<pipeline-name>/
├── <input-specific-filename>.<ext>    # NOT generic names
├── report_<input-specific>.md          # NOT generic "report.md"
└── metadata_<input-specific>.json     # NOT generic "metadata.json"
```

### Script Organization:
```bash
# Move testing scripts
scripts/pipeline_testing/
├── validate_all_pipelines.py
├── test_all_real_pipelines.py  
├── quick_validate.py
└── pipeline_validator.py

scripts/maintenance/
├── repository_organizer.py
├── safety_validator.py
└── cleanup_tools.py

scripts/production/
├── production_deploy.py
├── performance_monitor.py
└── quality_analyzer.py
```

## Quality Standards

### File Naming Conventions:
- **Input-Specific Naming**: Files named after their inputs, not generic names
- **Consistent Extensions**: .csv for data, .md for reports, .json for metadata
- **Descriptive Names**: Clear indication of content and source
- **Date Stamps**: When appropriate, use ISO format (YYYY-MM-DD)

### Directory Structure Rules:
- **No Nesting Beyond 3 Levels**: Keep directory trees shallow
- **Singular Names**: Use singular forms for directory names where logical
- **Consistent Naming**: snake_case for directories, kebab-case for files when needed
- **Clear Purpose**: Directory names should clearly indicate contents

### Documentation Requirements:
- **README in Every Major Directory**: Explain contents and purpose
- **Consistent Format**: Use standard README template
- **Up-to-Date Links**: All cross-references work after reorganization
- **Examples and Usage**: Show how to use contents

## Validation Checklist

### Pre-Move Validation:
- [ ] **Dependency Analysis**: Check what files reference what will be moved
- [ ] **Import Path Mapping**: Identify all import statements that will break
- [ ] **Link Reference Audit**: Find all documentation links that will break
- [ ] **Test Coverage**: Ensure tests cover critical file locations

### Post-Move Validation:
- [ ] **All Tests Pass**: Run full test suite after moves
- [ ] **Import Resolution**: All imports resolve correctly
- [ ] **Documentation Links**: All links work correctly
- [ ] **Pipeline Execution**: All example pipelines still work

### Quality Verification:
- [ ] **No Temporary Files**: Zero .tmp, debug_, temp_ files remain
- [ ] **Consistent Structure**: All directories follow naming conventions
- [ ] **Complete READMEs**: Every major directory has documentation
- [ ] **Working Examples**: All example pipelines execute successfully

## Integration with Other Tasks

### Supports Template Resolution (Task 001):
- Clean file paths make template resolution easier
- Consistent structure reduces template complexity
- Clear data locations improve template reliability

### Enables Quality Review (Task 003):
- Standardized output locations for LLM review
- Consistent naming for automated quality checks
- Clean structure for systematic validation

### Facilitates Testing (Task 004):
- Organized test script locations
- Clear separation of test vs production code
- Standardized output locations for test validation

## Risk Mitigation

### File Move Risks:
1. **Broken Dependencies**: Moving files breaks imports/references
   - **Mitigation**: Comprehensive dependency analysis before moves
2. **Test Failures**: Tests fail due to changed file locations
   - **Mitigation**: Update test configurations, run full test suite
3. **Pipeline Breaks**: Example pipelines fail due to moved data files
   - **Mitigation**: Test all pipelines after data file moves

### Quality Risks:
1. **Incomplete Cleanup**: Some temporary files missed
   - **Mitigation**: Systematic search patterns, automated cleanup verification
2. **Documentation Staleness**: Links become outdated after moves
   - **Mitigation**: Automated link checking, comprehensive documentation update

## Success Criteria

### Cleanup Success:
- ✅ **Zero Temporary Files**: No .tmp, debug_, temp_ files in repository
- ✅ **Clean Cache**: All cache directories removed or .gitignore'd
- ✅ **Organized Scripts**: All scripts in appropriate subdirectories
- ✅ **Consistent Structure**: All directories follow naming conventions

### Data Organization Success:
- ✅ **Consolidated Input Data**: All shared data in `examples/data/`
- ✅ **Standardized Outputs**: All pipeline outputs in `examples/outputs/<pipeline>/`
- ✅ **Input-Specific Naming**: No generic filenames in outputs
- ✅ **Test Data Separated**: Test-specific data isolated from examples

### Documentation Success:
- ✅ **Complete READMEs**: Every major directory documented
- ✅ **Working Links**: All cross-references functional
- ✅ **Consistent Format**: Standardized documentation structure
- ✅ **Clear Navigation**: Easy to find relevant information

### Quality Assurance:
- ✅ **All Tests Pass**: Full test suite successful after reorganization
- ✅ **Pipelines Work**: All example pipelines execute successfully
- ✅ **Professional Appearance**: Repository looks clean and organized
- ✅ **Maintainable Structure**: Easy to add new examples and documentation

## Expected Impact

### Developer Experience:
- **Easier Navigation**: Clear, logical directory structure
- **Faster Development**: Consistent patterns reduce cognitive load
- **Better Maintenance**: Organized structure easier to maintain
- **Professional Image**: Clean repository inspires confidence

### User Experience:
- **Clear Examples**: Easy to find and understand example pipelines
- **Consistent Outputs**: Predictable file locations and naming
- **Better Documentation**: Easy to find relevant tutorials and guides
- **Professional Quality**: Repository reflects platform quality standards
